@article{lindquist_brain_2012,
	title = {The brain basis of emotion: {A} meta-analytic review},
	volume = {35},
	issn = {1469-1825, 0140-525X},
	shorttitle = {The brain basis of emotion},
	url = {https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/brain-basis-of-emotion-a-metaanalytic-review/80F95F093305C76BA2C66BBA48D4BC8A},
	doi = {10.1017/S0140525X11000446},
	abstract = {Researchers have wondered how the brain creates emotions since the early days of psychological science. With a surge of studies in affective neuroscience in recent decades, scientists are poised to answer this question. In this target article, we present a meta-analytic summary of the neuroimaging literature on human emotion. We compare the locationist approach (i.e., the hypothesis that discrete emotion categories consistently and specifically correspond to distinct brain regions) with the psychological constructionist approach (i.e., the hypothesis that discrete emotion categories are constructed of more general brain networks not specific to those categories) to better understand the brain basis of emotion. We review both locationist and psychological constructionist hypotheses of brain–emotion correspondence and report meta-analytic findings bearing on these hypotheses. Overall, we found little evidence that discrete emotion categories can be consistently and specifically localized to distinct brain regions. Instead, we found evidence that is consistent with a psychological constructionist approach to the mind: A set of interacting brain regions commonly involved in basic psychological operations of both an emotional and non-emotional nature are active during emotion experience and perception across a range of discrete emotion categories.},
	language = {en},
	number = {3},
	urldate = {2025-04-05},
	journal = {Behavioral and Brain Sciences},
	author = {Lindquist, Kristen A. and Wager, Tor D. and Kober, Hedy and Bliss-Moreau, Eliza and Barrett, Lisa Feldman},
	month = jun,
	year = {2012},
	keywords = {meta-analysis, neuroimaging, Discrete emotion, emotion experience, emotion perception, psychological construction},
	pages = {121--143},
	file = {Full Text PDF:C\:\\Users\\super\\Zotero\\storage\\A5E64WCH\\Lindquist et al. - 2012 - The brain basis of emotion A meta-analytic review.pdf:application/pdf},
}

@article{de_borst_is_2015,
	title = {Is it the real deal? {Perception} of virtual characters versus humans: an affective cognitive neuroscience perspective},
	volume = {6},
	issn = {1664-1078},
	shorttitle = {Is it the real deal?},
	url = {http://www.frontiersin.org/Cognitive_Science/10.3389/fpsyg.2015.00576/abstract},
	doi = {10.3389/fpsyg.2015.00576},
	abstract = {Recent developments in neuroimaging research support the increased use of naturalistic stimulus material such as film, avatars, or androids. These stimuli allow for a better understanding of how the brain processes information in complex situations while maintaining experimental control. While avatars and androids are well suited to study human cognition, they should not be equated to human stimuli. For example, the uncanny valley hypothesis theorizes that artificial agents with high human-likeness may evoke feelings of eeriness in the human observer. Here we review if, when, and how the perception of human-like avatars and androids differs from the perception of humans and consider how this influences their utilization as stimulus material in social and affective neuroimaging studies. First, we discuss how the appearance of virtual characters affects perception. When stimuli are morphed across categories from non-human to human, the most ambiguous stimuli, rather than the most human-like stimuli, show prolonged classification times and increased eeriness. Human-like to human stimuli show a positive linear relationship with familiarity. Secondly, we show that expressions of emotions in human-like avatars can be perceived similarly to human emotions, with corresponding behavioral, physiological and neuronal activations, with exception of physical dissimilarities. Subsequently, we consider if and when one perceives differences in action representation by artificial agents versus humans. Motor resonance and predictive coding models may account for empirical findings, such as an interference effect on action for observed human-like, natural moving characters. However, the expansion of these models to explain more complex behavior, such as empathy, still needs to be investigated in more detail. Finally, we broaden our outlook to social interaction, where virtual reality stimuli can be utilized to imitate complex social situations.},
	language = {en},
	urldate = {2023-10-17},
	journal = {Frontiers in Psychology},
	author = {De Borst, Aline W. and De Gelder, Beatrice},
	month = may,
	year = {2015},
	file = {2015 - Is it the real deal- Perception of virtual characters versus humans- an affective cognitive neuroscience perspective.pdf:G\:\\My Drive\\School Work\\Ontario Tech\\Research\\Lit Review\\2015 - Is it the real deal- Perception of virtual characters versus humans- an affective cognitive neuroscience perspective.pdf:application/pdf},
}

@article{kawasaki_processing_2012,
	title = {Processing of {Facial} {Emotion} in the {Human} {Fusiform} {Gyrus}},
	volume = {24},
	issn = {0898-929X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3566877/},
	doi = {10.1162/jocn_a_00175},
	abstract = {Electrophysiological and fMRI-based investigations of the ventral temporal cortex of primates provide strong support for regional specialization for the processing of faces. These responses are most frequently found in or near the fusiform gyrus, but there is substantial variability in their anatomical location and response properties. An outstanding question is the extent to which ventral temporal cortex participates in processing dynamic, expressive aspects of faces, a function usually attributed to regions near the superior temporal cortex. Here, we investigated these issues through intracranial recordings from eight human surgical patients. We compared several different aspects of face processing (static and dynamic faces; happy, neutral, and fearful expressions) with power in the high-gamma band (70–150 Hz) from a spectral analysis. Detailed mapping of the response characteristics as a function of anatomical location was conducted in relation to the gyral and sulcal pattern on each patient’s brain. The results document responses with high responsiveness for static or dynamic faces, often showing abrupt changes in response properties between spatially close recording sites and idiosyncratic across different subjects. Notably, strong responses to dynamic facial expressions can be found in the fusiform gyrus, just as can responses to static faces. The findings suggest a more complex, fragmented architecture of ventral temporal cortex around the fusiform gyrus, one that includes focal regions of cortex that appear relatively specialized for either static or dynamic aspects of faces.},
	number = {6},
	urldate = {2025-04-23},
	journal = {Journal of cognitive neuroscience},
	author = {Kawasaki, Hiroto and Tsuchiya, Naotsugu and Kovach, Christopher K. and Nourski, Kirill V. and Oya, Hiroyuki and Howard, Matthew A. and Adolphs, Ralph},
	month = jun,
	year = {2012},
	pmid = {22185494},
	pmcid = {PMC3566877},
	pages = {1358--1370},
	file = {Full Text PDF:C\:\\Users\\super\\Zotero\\storage\\98FMLVVN\\Kawasaki et al. - 2012 - Processing of Facial Emotion in the Human Fusiform.pdf:application/pdf},
}

@article{sato_amygdala_2004,
	title = {The amygdala processes the emotional significance of facial expressions: an {fMRI} investigation using the interaction between expression and face direction},
	volume = {22},
	issn = {1053-8119},
	shorttitle = {The amygdala processes the emotional significance of facial expressions},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811904001235},
	doi = {10.1016/j.neuroimage.2004.02.030},
	abstract = {Neuroimaging studies have shown activity in the amygdala in response to facial expressions of emotion, but the specific role of the amygdala remains unknown. We hypothesized that the amygdala is involved in emotional but not basic sensory processing for facial expressions. To test this hypothesis, we manipulated the face directions of emotional expressions in the unilateral visual fields; this manipulation made it possible to alter the emotional significance of the facial expression for the observer without affecting the physical features of the expression. We presented angry/neutral expressions looking toward/away from the subject and depicted brain activity using fMRI. After the image acquisitions, the subject's experience of negative emotion when perceiving each stimulus was also investigated. The left amygdala showed the interaction between emotional expression and face direction, indicating higher activity for angry expressions looking toward the subjects than angry expressions looking away from them. The experienced emotion showed the corresponding interaction. Regression analysis showed a positive relation between the left amygdala activity and experienced emotion. These results suggest that the amygdala is involved in emotional but not visuoperceptual processing for emotional facial expressions, which specifically includes the decoding of emotional significance and elicitation of one's own emotions corresponding to that significance.},
	number = {2},
	urldate = {2025-04-23},
	journal = {NeuroImage},
	author = {Sato, Wataru and Yoshikawa, Sakiko and Kochiyama, Takanori and Matsumura, Michikazu},
	month = jun,
	year = {2004},
	keywords = {Amygdala, Emotional facial expressions, Experienced emotion, Face direction, fMRI},
	pages = {1006--1013},
	file = {1-s2.0-S1053811904001235-main.pdf:C\:\\Users\\super\\Downloads\\1-s2.0-S1053811904001235-main.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\super\\Zotero\\storage\\894GE34Q\\S1053811904001235.html:text/html},
}

@article{saarimaki_classification_2022,
	title = {Classification of emotion categories based on functional connectivity patterns of the human brain},
	volume = {247},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811921010715},
	doi = {10.1016/j.neuroimage.2021.118800},
	abstract = {Neurophysiological and psychological models posit that emotions depend on connections across wide-spread corticolimbic circuits. While previous studies using pattern recognition on neuroimaging data have shown differences between various discrete emotions in brain activity patterns, less is known about the differences in functional connectivity. Thus, we employed multivariate pattern analysis on functional magnetic resonance imaging data (i) to develop a pipeline for applying pattern recognition in functional connectivity data, and (ii) to test whether connectivity patterns differ across emotion categories. Six emotions (anger, fear, disgust, happiness, sadness, and surprise) and a neutral state were induced in 16 participants using one-minute-long emotional narratives with natural prosody while brain activity was measured with functional magnetic resonance imaging (fMRI). We computed emotion-wise connectivity matrices both for whole-brain connections and for 10 previously defined functionally connected brain subnetworks and trained an across-participant classifier to categorize the emotional states based on whole-brain data and for each subnetwork separately. The whole-brain classifier performed above chance level with all emotions except sadness, suggesting that different emotions are characterized by differences in large-scale connectivity patterns. When focusing on the connectivity within the 10 subnetworks, classification was successful within the default mode system and for all emotions. We thus show preliminary evidence for consistently different sustained functional connectivity patterns for instances of emotion categories particularly within the default mode system.},
	urldate = {2025-04-23},
	journal = {NeuroImage},
	author = {Saarimäki, Heini and Glerean, Enrico and Smirnov, Dmitry and Mynttinen, Henri and Jääskeläinen, Iiro P. and Sams, Mikko and Nummenmaa, Lauri},
	month = feb,
	year = {2022},
	keywords = {Emotion, fMRI, Functional connectivity, MVPA, Pattern classification},
	pages = {118800},
	file = {1-s2.0-S1053811921010715-main.pdf:C\:\\Users\\super\\Downloads\\1-s2.0-S1053811921010715-main.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\super\\Zotero\\storage\\WNGACV8F\\S1053811921010715.html:text/html},
}
