{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports/Pick Analyses to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nilearn\\glm\\__init__.py:55: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  warn('The nilearn.glm module is experimental. '\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import mne\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import re\n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import mixedlm, ols\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import statsmodels.api as sm\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "\n",
    "from preprocess_nirs import *\n",
    "from nirs_functions import *\n",
    "\n",
    "from mne_nirs.channels import picks_pair_to_idx, get_long_channels\n",
    "from mne_nirs.preprocessing import peak_power, scalp_coupling_index_windowed\n",
    "from mne.preprocessing.nirs import source_detector_distances, scalp_coupling_index\n",
    "from mne_connectivity import spectral_connectivity_time\n",
    "from mne_connectivity.viz import plot_connectivity_circle\n",
    "from mne.viz import circular_layout\n",
    "from mne_nirs.statistics import run_glm, statsmodels_to_results\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set the image dpi\n",
    "dpi = 600\n",
    "\n",
    "# Set the number of cores to use\n",
    "n_jobs = 1\n",
    "if os.cpu_count() is not None:\n",
    "    n_jobs = int(np.ceil(os.cpu_count() * 0.75))\n",
    "\n",
    "seed_value = 42\n",
    "# Set the random seed\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.keras.utils.set_random_seed(seed_value)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Get the mappings of the brain regions\n",
    "mappings = json.load(open(\"processed_data/mappings/mappings.json\"))\n",
    "\n",
    "# Set thresholds for the data\n",
    "sci_threshold = 0.5\n",
    "cv_threshold = 15\n",
    "good_threshold = 0.7\n",
    "peak_power_threshold = 0.1\n",
    "behavioural_accuracy_threshold = 0.6\n",
    "max_times = 104\n",
    "\n",
    "# Preprocess the data\n",
    "process_data = False\n",
    "\n",
    "# Get the participant info plots\n",
    "get_participant_age_plot = False\n",
    "get_meas_dates_plot = False\n",
    "get_short_chns_plot = False\n",
    "get_behavioural_responses = False\n",
    "no_response_counts = False\n",
    "run_behavioural_responses_stats = False\n",
    "get_behavioural_responses_plots = False\n",
    "\n",
    "# Get the mappings\n",
    "get_mappings = False\n",
    "\n",
    "# Get the non windowed SCI and CV measure\n",
    "get_full_sci = False\n",
    "get_full_cv = False\n",
    "\n",
    "# Get the peak power/scalp coupling index dataframes\n",
    "get_peak_power_sci_df = False\n",
    "get_good_windows_plot = False\n",
    "get_slope_pp_sci_plot = False\n",
    "get_head_size_vs_sci_plot = False\n",
    "get_across_participant_sci_plots = False\n",
    "get_participant_sci_plots = False\n",
    "\n",
    "# Get the epochs\n",
    "get_epoch_data = False\n",
    "\n",
    "# Get the GLM data/plots\n",
    "get_glm_design_matrix_plot = False\n",
    "get_glm_analysis = False\n",
    "get_ind_glm_plots = False\n",
    "get_group_glm_plots = False\n",
    "get_group_contrast_plots = False\n",
    "get_sig_group_contrast_table = False\n",
    "\n",
    "# Get the average timeseries activity\n",
    "get_roi_timeseries_activity = False\n",
    "\n",
    "# Get the ERP plots\n",
    "get_erp_plots = False\n",
    "\n",
    "# Get the connectivity data\n",
    "run_ind_connectivity = False\n",
    "get_condition_con_plots = False\n",
    "get_variance_con_plots = False\n",
    "run_group_level_t_tests = False\n",
    "get_group_level_t_tests_chord_plots = False\n",
    "get_group_level_t_tests_roi_chord_plots = False\n",
    "get_emotion_analysis_plots = False\n",
    "\n",
    "# Run decoding analysis\n",
    "run_traditional_raw_across_decoding = False\n",
    "run_dl_raw_across_decoding = True\n",
    "run_traditional_con_across_decoding = False\n",
    "\n",
    "# Get the decoding plots\n",
    "get_decoding_table_scores_plots = True\n",
    "get_decoding_individual_scores_plots = True\n",
    "\n",
    "raws = []\n",
    "raw_ods = []\n",
    "raw_haemos = []\n",
    "raw_haemo_good_recordings = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder path\n",
    "data_path = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "# Get a list of paths of all the subfolders of the folders labeled 'P_1', 'P_2', etc.\n",
    "participants = [os.path.join(data_path, f) for f in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, f))]\n",
    "\n",
    "participants_with_same_order = []\n",
    "\n",
    "# remove participants P_1 to P_11 but keep P_10, and P_12 onwards\n",
    "# P_1 to P_11 have the same order of faces, and P_86 and P_87 have the same order of faces\n",
    "for i in range(1, 12):\n",
    "    if i != 10:\n",
    "        participants_with_same_order.append(os.path.join(data_path, f'P_{i}'))\n",
    "        #participants.remove(os.path.join(data_path, f'P_{i}'))\n",
    "\n",
    "participants_with_same_order.append(os.path.join(data_path, f'P_87'))\n",
    "#participants.remove(os.path.join(data_path, f'P_87'))\n",
    "\n",
    "# remove participants P_13 due to not recording\n",
    "participants.remove(os.path.join(data_path, f'P_13'))\n",
    "\n",
    "# remove participants P_50 due to ending early\n",
    "participants.remove(os.path.join(data_path, f'P_50'))\n",
    "\n",
    "# participant P_54 used their phone\n",
    "participants.remove(os.path.join(data_path, f'P_54'))\n",
    "\n",
    "# participant P_75 did not have Real_Fear\n",
    "participants.remove(os.path.join(data_path, f'P_75'))\n",
    "\n",
    "# Search recursively for the folder with the .snirf extension\n",
    "fnirs_folders = []\n",
    "for participant in participants:\n",
    "    for root, dirs, files in os.walk(participant):\n",
    "        for file in files:\n",
    "            if file.endswith('.snirf'):\n",
    "                fnirs_folders.append(root)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    if process_data:\n",
    "        raws = []\n",
    "        raw_ods = []\n",
    "        raw_haemos = []\n",
    "\n",
    "        # Load the snirf files\n",
    "        for folder in fnirs_folders:\n",
    "            # find all the .snirf files in the folder but get the full path\n",
    "            snirf_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.snirf')]\n",
    "            if len(snirf_files) == 0:\n",
    "                print(f\"No .snirf files found in {folder}\")\n",
    "                continue\n",
    "            elif len(snirf_files) > 1:\n",
    "                raise Exception(f\"Multiple .snirf files found in {folder}\")\n",
    "            else:\n",
    "                raw = mne.io.read_raw_snirf(snirf_files[0], optode_frame='mri', preload=True, verbose=False)\n",
    "            \n",
    "            # find all the 'description.json' files in the folder but get the full path\n",
    "            description_files = [f for f in os.listdir(folder) if 'description.json' in f]\n",
    "            if len(description_files) == 0:\n",
    "                print(f\"No description.json files found in {folder}\")\n",
    "                continue\n",
    "            elif len(description_files) > 1:\n",
    "                raise Exception(f\"Multiple description.json files found in {folder}\")\n",
    "            else:\n",
    "                description = json.load(open(os.path.join(folder, description_files[0])))\n",
    "                # get the parent's parent folder name\n",
    "                parent_folder = os.path.basename(os.path.dirname(folder))\n",
    "                # find the .csv file in the parent folder\n",
    "                csv_files = [f for f in os.listdir(os.path.join(data_path, parent_folder)) if f.endswith('.csv')]\n",
    "                if len(csv_files) == 0:\n",
    "                    print(f\"No .csv files found in {os.path.join(data_path, parent_folder)}\")\n",
    "                elif len(csv_files) > 1:\n",
    "                    raise Exception(f\"Multiple .csv files found in {os.path.join(data_path, parent_folder)}\")\n",
    "                else:\n",
    "                    # add the path to the .csv file to the description\n",
    "                    description['behavioural_data'] = os.path.join(data_path, parent_folder, csv_files[0])\n",
    "\n",
    "            distances = np.array(source_detector_distances(raw.info))\n",
    "            distance_counts = {\n",
    "                \"short\": int(sum(distances < 0.01)),\n",
    "                \"long\": int(sum(distances >= 0.01))\n",
    "            }\n",
    "\n",
    "            description['distance_counts'] = distance_counts\n",
    "\n",
    "            # add the description to the raw object\n",
    "            raw.info['description'] = str(description)\n",
    "            raws.append(raw)\n",
    "\n",
    "        # sort the raws by the measurement date\n",
    "        raws = sorted(raws, key=lambda x: x.info['meas_date'])\n",
    "\n",
    "        i = 1\n",
    "        for raw in raws:\n",
    "            raw_od, raw_haemo = preprocess_data(raw)\n",
    "            raw_ods.append(raw_od)\n",
    "            raw_haemos.append(raw_haemo)\n",
    "            i += 1\n",
    "\n",
    "        # clear any files in each folder\n",
    "        for folder in ['processed_data/raws', 'processed_data/raw_ods', 'processed_data/raw_haemos']:\n",
    "            for f in os.listdir(folder):\n",
    "                os.remove(os.path.join(folder, f))\n",
    "\n",
    "        for i, (raw, raw_od, raw_haemo) in enumerate(zip(raws, raw_ods, raw_haemos), 1):\n",
    "            # save raw as a fif file\n",
    "            raw.save(f'processed_data/raws/raw{i}.fif', overwrite=True, verbose=False)\n",
    "\n",
    "            # save raw_od as a fif file\n",
    "            raw_od.save(f'processed_data/raw_ods/raw_od{i}.fif', overwrite=True, verbose=False)\n",
    "\n",
    "            # save raw_haemo as a fif file\n",
    "            raw_haemo.save(f'processed_data/raw_haemos/raw_haemo{i}.fif', overwrite=True, verbose=False)\n",
    "        \n",
    "        raws = []\n",
    "        raw_ods = []\n",
    "        raw_haemos = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Participant Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Participant Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_participant_age_plot:\n",
    "    good_recordings = True\n",
    "    if good_recordings:\n",
    "        # Load the good recordings\n",
    "        raw_haemos = load_data('raw_haemos', 'good') if len(raw_haemos) == 0 else raw_haemos\n",
    "        title = \"age_distribution_good\"\n",
    "    else:\n",
    "        # Load all recordings\n",
    "        raw_haemos = load_data('raw_haemos') if len(raw_haemos) == 0 else raw_haemos\n",
    "        title = \"age_distribution_all\"\n",
    "\n",
    "    ages = []\n",
    "    for raw_haemo in raw_haemos:\n",
    "        description = get_info(raw_haemo)\n",
    "        age = description['age']\n",
    "        ages.append(age)\n",
    "\n",
    "    # Convert ages to numeric type\n",
    "    ages = np.array(ages, dtype=float)\n",
    "\n",
    "    # Sort the ages\n",
    "    ages = sorted(ages)\n",
    "\n",
    "    # Get the number of participants\n",
    "    n_participants = len(ages)\n",
    "\n",
    "    # Get the mean and standard deviation of the ages\n",
    "    mean_age = np.mean(ages)\n",
    "    std_age = np.std(ages)\n",
    "\n",
    "    # Get the minimum and maximum ages\n",
    "    min_age = min(ages)\n",
    "    max_age = max(ages)\n",
    "    \n",
    "    # Plot the ages in a histogram\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(ages, bins=30, color='blue', alpha=0.7)\n",
    "    plt.xlabel('Age (years)', fontsize=14)\n",
    "    plt.ylabel('Count', fontsize=14)\n",
    "    plt.title(f'Age Distribution of Participants\\nN ={n_participants}, Mean={mean_age:.2f}, SD={std_age:.2f}, Min={min_age}, Max={max_age}', fontsize=16)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/participants/' + title + '.png', dpi=dpi / 2)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurement Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_meas_dates_plot:\n",
    "    raw_haemos = load_data('raw_haemos') if len(raw_haemos) == 0 else raw_haemos\n",
    "\n",
    "    # Extract the measurement dates\n",
    "    measurement_dates = [raw_haemo.info['meas_date'] for raw_haemo in raw_haemos]\n",
    "\n",
    "    # Convert to pandas datetime\n",
    "    measurement_dates = pd.to_datetime(measurement_dates)\n",
    "\n",
    "    # Create a plot of the measurement dates\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(measurement_dates, range(1, len(measurement_dates) + 1), 'o-')\n",
    "    plt.xlabel('Measurement date')\n",
    "    plt.ylabel('Participant number')\n",
    "    plt.title('Measurement dates of participants, N = ' + str(len(measurement_dates)))\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/participants/measurement_dates.png', dpi=dpi / 4)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Distance Channels Distribution Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_short_chns_plot:\n",
    "    raw_haemo_good_recordings = load_data('raw_haemos', 'good') if len(raw_haemo_good_recordings) == 0 else raw_haemo_good_recordings\n",
    "    \n",
    "    total_short_chns = []\n",
    "    for raw_haemo in raw_haemo_good_recordings:\n",
    "        num_short_chns = get_info(raw_haemo)['distance_counts']['short']\n",
    "        total_short_chns.append(num_short_chns)\n",
    "    total_short_chns = np.array(total_short_chns)\n",
    "\n",
    "    # plot a pie chart of the number of short channels\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.pie(Counter(total_short_chns).values(), labels=Counter(total_short_chns).keys(), autopct='%1.1f%%')\n",
    "    plt.title('Distribution of number of short channels across good recordings, N = ' + str(len(total_short_chns)))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/participants/short_channels.png', dpi=dpi / 4)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Behavioural Responses Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_behavioural_responses:\n",
    "    raw_haemos = load_data('raw_haemos') if len(raw_haemos) == 0 else raw_haemos\n",
    "\n",
    "    participant_scores = pd.DataFrame()\n",
    "    for i, raw_haemo in enumerate(raw_haemos, 1):\n",
    "        path = get_info(raw_haemo)['behavioural_data']\n",
    "\n",
    "        # folder_name = (P_(\\d+))\n",
    "        folder_name = re.search(r'P_(\\d+)', path).group(0)\n",
    "\n",
    "        # read the csv file\n",
    "        behavioural_data = pd.read_csv(path)\n",
    "\n",
    "        # only keep the first 6 columns and the column called \"key_resp.keys\"\n",
    "        behavioural_data = behavioural_data.iloc[:, :6].join(behavioural_data[['key_resp.keys', 'key_resp.rt']])\n",
    "\n",
    "        # remove the \"blocknumber\" column\n",
    "        behavioural_data = behavioural_data.drop(columns='blocknumber')\n",
    "\n",
    "        # remove the first row and reset the index\n",
    "        behavioural_data = behavioural_data.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "        # divide the dataframe into rows of 9\n",
    "        behavioural_data = [behavioural_data.iloc[i:i + 9] for i in range(0, len(behavioural_data), 9)]\n",
    "\n",
    "        scores = []\n",
    "        for j, data in enumerate(behavioural_data, 1):\n",
    "            # in the last row, save the \"key_resp.keys\" column\n",
    "            response = data['key_resp.keys'].iloc[-1]\n",
    "\n",
    "            # convert the response to a boolean\n",
    "            response = {'n': False, 'y': True}.get(response, np.nan)\n",
    "            \n",
    "            # in the last row, copy the \"tasknames\" and \"taskmarkers\" value to \"filepaths\" and \"marker\" respectively\n",
    "            data.loc[data.index[-1], [\"filepaths\", \"marker\"]] = [data[\"tasknames\"].iloc[-1], data[\"taskmarker\"].iloc[-1]]\n",
    "\n",
    "            # remove the \"tasknames\" and \"taskmarker\" columns\n",
    "            data = data.drop(columns=[\"tasknames\", \"taskmarker\"])\n",
    "\n",
    "            # check if the (marker - 2000) in the last row was in any of the other rows\n",
    "            correct_response = (data['marker'].iloc[-1] - 2000) in data['marker'].values\n",
    "\n",
    "            # append the data to the scores list\n",
    "            scores.append({\n",
    "                'Participant': i,\n",
    "                'Trial': j,\n",
    "                'Block Name': data['blocknames'].iloc[-1],\n",
    "                'File Path': data['filepaths'].iloc[-1],\n",
    "                'Marker': data['marker'].iloc[-1],\n",
    "                'Response Time': data['key_resp.rt'].iloc[-1],\n",
    "                'Response': response,\n",
    "                'Correct Response': correct_response\n",
    "            })\n",
    "        \n",
    "        # append the scores to the participant_scores dataframe\n",
    "        participant_scores = pd.concat([participant_scores, pd.DataFrame(scores)])\n",
    "\n",
    "    # for each row, if \"Response\" == \"Correct Response\", create a new column called \"Correct\" and set it to True, else False, if the \"Response\" is NaN, set it to NaN, don't get rid of the \"Correct Response\" column\n",
    "    participant_scores['Correct'] = participant_scores.apply(\n",
    "        lambda x: np.nan if pd.isna(x['Response']) else bool(x['Response']) == bool(x['Correct Response']), axis=1\n",
    "    )\n",
    "\n",
    "    # subtract 2000 from the \"Marker\" column\n",
    "    participant_scores['Marker'] = participant_scores['Marker'] - 2000\n",
    "\n",
    "    # for each row in 'Marker' replace it with two columns 'Face Type' and 'Emotion' from the trigger_decoder function, which returns a tuple\n",
    "    participant_scores[['Face Type', 'Emotion']] = participant_scores['Marker'].apply(trigger_decoder).apply(pd.Series)\n",
    "\n",
    "    # remove the \"Block Name\", \"File Path\", \"Marker\", columns\n",
    "    participant_scores = participant_scores.drop(columns=[\"Block Name\", \"File Path\", \"Marker\"])\n",
    "\n",
    "    # move \"Face Type\" and \"Emotion\" to after Participant\n",
    "    participant_scores = participant_scores[['Participant', 'Trial', 'Face Type', 'Emotion', 'Response Time', 'Response', 'Correct Response', 'Correct']]\n",
    "\n",
    "    # save the participant_scores dataframe\n",
    "    participant_scores.to_csv('processed_data/behavioural_responses/participant_scores.csv', index=False)\n",
    "\n",
    "# Load the participant scores\n",
    "participant_scores = pd.read_csv('processed_data/behavioural_responses/participant_scores.csv')\n",
    "\n",
    "# get and save the original participant scores before dropping any participants\n",
    "participant_scores_original = participant_scores.copy()\n",
    "\n",
    "# get the number of Correct responses per participant\n",
    "correct_responses = participant_scores.groupby('Participant')['Correct'].sum()\n",
    "\n",
    "# get the indices of the participants with > 60% correct responses\n",
    "good_recordings = correct_responses[correct_responses > 56 * behavioural_accuracy_threshold].index\n",
    "\n",
    "# only keep the participants with > accuracy_threshold correct responses\n",
    "participant_scores = participant_scores[participant_scores['Participant'].isin(good_recordings)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if no_response_counts:\n",
    "    # filter participant_scores to only include the trials with a nan value in the 'Response' column\n",
    "    no_response = participant_scores[participant_scores['Response'].isna()]\n",
    "\n",
    "    # count the number of rows per participant\n",
    "    no_response_counts = no_response['Participant'].value_counts()\n",
    "\n",
    "    # make a histogram of the number of trials with no response per participant\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bins = range(1, no_response_counts.values.max() + 2)\n",
    "    n, bins, patches = plt.hist(no_response_counts.values, bins=bins, color='gold', alpha=0.7, edgecolor='black')\n",
    "\n",
    "    # Apply a gradient color to each bar using a colormap\n",
    "    cmap = plt.cm.Wistia\n",
    "    for i, patch in enumerate(patches):\n",
    "        color = cmap(i / len(patches))\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "    plt.xlabel('Number of Blocks with No Response', fontsize=14)\n",
    "    plt.ylabel('Number of Participants', fontsize=14)\n",
    "    plt.title('Distribution of Blocks with No Response per Participant', fontsize=16)\n",
    "    plt.xticks(\n",
    "        ticks=[b + 0.5 for b in bins[:-1]],\n",
    "        labels=[str(b) for b in bins[:-1]]\n",
    "    )\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig('plots/behavioural_responses/no_response_counts.png', dpi=dpi / 2)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Behavioural Responses Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_behavioural_responses_stats:\n",
    "    # Create a copy of the 'Correct' column and convert it to 1 if True, 0 if False\n",
    "    participant_scores['Correct Numeric'] = np.where(participant_scores['Correct'] == True, 1, 0)\n",
    "    participant_scores_original['Correct Numeric'] = np.where(participant_scores_original['Correct'] == True, 1, 0)\n",
    "\n",
    "    # Create a copy of the relevant columns\n",
    "    data_copy = participant_scores[['Face Type', 'Emotion', 'Correct Numeric']].copy()\n",
    "\n",
    "    # Rename the column for consistency\n",
    "    data_copy = data_copy.rename(columns={'Face Type': 'Face_Type', 'Correct Numeric': 'Correct_Numeric'})\n",
    "\n",
    "    # Build an OLS model including Face Type, Emotion, and their interaction\n",
    "    model = ols(\"Correct_Numeric ~ C(Face_Type) * C(Emotion)\", data=data_copy).fit()\n",
    "\n",
    "    # Perform two-way ANOVA\n",
    "    anova_table = sm.stats.anova_lm(model, typ=3)  # Type 3 ANOVA\n",
    "\n",
    "    # Print the ANOVA table with p-values not in scientific notation\n",
    "    anova_table['PR(>F)'] = anova_table['PR(>F)'].apply(lambda x: f\"{x:.6f}\" if not pd.isnull(x) else x)\n",
    "\n",
    "    # save the anova table\n",
    "    anova_table.to_csv('processed_data/behavioural_responses/anova_table.csv')\n",
    "\n",
    "    p_value_face_type = anova_table.loc['C(Face_Type)', 'PR(>F)']\n",
    "    p_value_emotion = anova_table.loc['C(Emotion)', 'PR(>F)']\n",
    "    p_value_interaction = anova_table.loc['C(Face_Type):C(Emotion)', 'PR(>F)']\n",
    "\n",
    "    # Check if there is a significant correlation between Response Time and Correct\n",
    "    # Ensure both columns have the same length by dropping NaN values in both simultaneously\n",
    "    valid_data = participant_scores[['Response Time', 'Correct Numeric']].dropna()\n",
    "    correlation, p_value = stats.pearsonr(valid_data['Response Time'], valid_data['Correct Numeric'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Behavioural Responses Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_behavioural_responses_plots:\n",
    "    # get the sum of correct responses for each participant\n",
    "    participant_correct_responses = participant_scores.groupby('Participant')['Correct'].sum()\n",
    "    participant_correct_responses_original = participant_scores_original.groupby('Participant')['Correct'].sum()\n",
    "\n",
    "    n_blocks = len(participant_scores) / len(participant_scores['Participant'].unique())\n",
    "    n_blocks_original = len(participant_scores_original) / len(participant_scores_original['Participant'].unique())\n",
    "\n",
    "    # plot this data\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(participant_correct_responses_original.index, participant_correct_responses_original.values, width=0.9)\n",
    "    plt.axhline(y=n_blocks_original * behavioural_accuracy_threshold, color='r', linestyle='--', label='Accuracy Threshold')\n",
    "    plt.xlabel('Participant', fontsize=16)\n",
    "    plt.ylabel('Number of Correct Responses', fontsize=16)\n",
    "    plt.title('Number of Correct Responses per Participant\\nMean across all ' + str(len(participant_correct_responses_original)) + ' participants: ' + str(round(participant_correct_responses_original.mean() / n_blocks_original * 100, 2)) + '%', fontsize=24)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/behavioural_responses/correct_responses_by_participant.png', dpi=dpi // 2)\n",
    "    plt.close()\n",
    "\n",
    "    # get the percentage of correct responses for each type of face and emotion and the combination of both\n",
    "    face_type_correct_responses = participant_scores.groupby('Face Type')['Correct'].mean() * 100\n",
    "    emotion_correct_responses = participant_scores.groupby('Emotion')['Correct'].mean() * 100\n",
    "    face_type_emotion_correct_responses = participant_scores.groupby(['Face Type', 'Emotion'])['Correct'].mean() * 100\n",
    "\n",
    "    # Create a figure and specify a 2x2 GridSpec\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    gs = fig.add_gridspec(2, 2)  # 2 rows, 2 columns\n",
    "\n",
    "    plt.suptitle('Correct Memory Task Responses by Face Type and Emotion', fontsize=16)\n",
    "\n",
    "    # Top-left: Face Type pie chart\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.pie(face_type_correct_responses,\n",
    "            labels=face_type_correct_responses.index,\n",
    "            autopct='%1.1f%%', startangle=90, radius=1)\n",
    "    ax1.set_title('Face Type\\np = ' + str(p_value_face_type))\n",
    "\n",
    "    # Top-right: Emotion pie chart\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.pie(emotion_correct_responses,\n",
    "            labels=emotion_correct_responses.index,\n",
    "            autopct='%1.1f%%', startangle=90, radius=1)\n",
    "    ax2.set_title('Emotion\\np = ' + str(p_value_emotion))\n",
    "\n",
    "    # Bottom row spanning both columns: Face Type & Emotion pie chart\n",
    "    ax3 = fig.add_subplot(gs[1, :])  # span columns 0 and 1\n",
    "    ax3.pie(face_type_emotion_correct_responses,\n",
    "            labels=[f\"{ft}-{em}\" for ft, em in face_type_emotion_correct_responses.index],\n",
    "            autopct='%1.1f%%', startangle=90, radius=1)\n",
    "    ax3.set_title('Face Type & Emotion\\np = ' + str(p_value_interaction))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/behavioural_responses/correct_responses_by_face_type_emotion.png', dpi=dpi / 4)\n",
    "    plt.close()\n",
    "\n",
    "    # get the average number of correct responses for each trial\n",
    "    trial_correct_responses = participant_scores.groupby('Trial')['Correct'].mean().to_list()\n",
    "\n",
    "    # calculate the regression line using stats.linregress\n",
    "    x = range(1, len(trial_correct_responses) + 1)\n",
    "    y = trial_correct_responses\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "    # plot this data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(trial_correct_responses) + 1), trial_correct_responses, 'o-')\n",
    "    plt.plot(x, [slope * i + intercept for i in x], 'r--')\n",
    "    plt.xlabel('Trial')\n",
    "    plt.ylabel('Percentage of Correct Responses')\n",
    "    plt.title('Percentage of Correct Responses per Trial, R^2 = ' + str(round(r_value ** 2, 2)) + ', p = ' + str(round(p_value, 4)))\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/behavioural_responses/correct_responses_by_trial.png', dpi=dpi / 4)\n",
    "    plt.close()\n",
    "\n",
    "    # get the average response time for each trial\n",
    "    trial_response_times = participant_scores.groupby('Trial')['Response Time'].mean().to_list()\n",
    "    \n",
    "    # calculate the regression line using stats.linregress\n",
    "    x = range(1, len(trial_response_times) + 1)\n",
    "    y = trial_response_times\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "    \n",
    "    # plot this data\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(range(1, len(trial_response_times) + 1), trial_response_times, 'o-')\n",
    "    plt.plot(x, [slope * i + intercept for i in x], 'r--')\n",
    "    plt.xlabel('Trial')\n",
    "    plt.ylabel('Response Time (s)')\n",
    "    plt.title('Response Time per Trial, R^2 = ' + str(round(r_value ** 2, 2)) + ', p = ' + str(p_value) + '\\nCorrelation with Correct answer: ' + str(round(correlation, 4)))\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/behavioural_responses/response_times_by_trial.png', dpi=dpi)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping brain regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_mappings:\n",
    "    raw_haemos = load_data('raw_haemos') if len(raw_haemos) == 0 else raw_haemos\n",
    "\n",
    "    # get the channel names for hbo\n",
    "    ch_names_hbo = [ch_name for ch_name in raw_haemos[0].ch_names if 'hbo' in ch_name]\n",
    "\n",
    "    ch_mapping_hbo = {\n",
    "        \"Left Frontal\": [],\n",
    "        \"Right Frontal\": [],\n",
    "        \"Left Prefrontal\": [],\n",
    "        \"Right Prefrontal\": [],\n",
    "        \"Left Parietal\": [],\n",
    "        \"Right Parietal\": [],\n",
    "        \"Left Occipital\": [],\n",
    "        \"Right Occipital\": []\n",
    "    }\n",
    "\n",
    "    group_boundaries = [0]\n",
    "\n",
    "    ch_mapping_hbo[\"Left Frontal\"].append('S1_D1 hbo')\n",
    "\n",
    "    ch_mapping_hbo[\"Left Frontal\"].append('S1_D2 hbo')\n",
    "\n",
    "    ch_mapping_hbo[\"Left Frontal\"].append('S6_D3 hbo')\n",
    "\n",
    "    ch_mapping_hbo[\"Left Frontal\"].append('S6_D31 hbo')\n",
    "\n",
    "    # find the channels that have 'S2_', 'S3_', 'S4_', 'S5_' in them\n",
    "    for ch_name in [ch_name for ch_name in ch_names_hbo if 'S2_' in ch_name or 'S3_' in ch_name or 'S4_' in ch_name or 'S5_' in ch_name]:\n",
    "        ch_mapping_hbo[\"Left Frontal\"].append(ch_name)\n",
    "\n",
    "    group_boundaries.append(len(ch_mapping_hbo[\"Left Frontal\"]))\n",
    "\n",
    "    ch_mapping_hbo[\"Right Frontal\"].append('S1_D17 hbo')\n",
    "\n",
    "    ch_mapping_hbo[\"Right Frontal\"].append('S6_D2 hbo')\n",
    "\n",
    "    ch_mapping_hbo[\"Right Frontal\"].append('S6_D18 hbo')\n",
    "\n",
    "    # find the channels that have 'S9_', 'S10_', 'S11_', 'S12_' in them\n",
    "    for ch_name in [ch_name for ch_name in ch_names_hbo if 'S9_' in ch_name or 'S10_' in ch_name or 'S11_' in ch_name or 'S12_' in ch_name]:\n",
    "        ch_mapping_hbo[\"Right Frontal\"].append(ch_name)\n",
    "\n",
    "    group_boundaries.append(len(ch_mapping_hbo[\"Right Frontal\"]) + group_boundaries[-1])\n",
    "\n",
    "    # find the channels that have 'S7_', 'S8_', 'S25_', 'S26_' in them\n",
    "    for ch_name in [ch_name for ch_name in ch_names_hbo if 'S7_' in ch_name or 'S8_' in ch_name or 'S25_' in ch_name or 'S26_' in ch_name]:\n",
    "        ch_mapping_hbo[\"Left Prefrontal\"].append(ch_name)\n",
    "\n",
    "    group_boundaries.append(len(ch_mapping_hbo[\"Left Prefrontal\"]) + group_boundaries[-1])\n",
    "\n",
    "    # find the channels that have 'S13_', 'S14_', 'S15_', 'S16_' in them\n",
    "    for ch_name in [ch_name for ch_name in ch_names_hbo if 'S13_' in ch_name or 'S14_' in ch_name or 'S15_' in ch_name or 'S16_' in ch_name]:\n",
    "        ch_mapping_hbo[\"Right Prefrontal\"].append(ch_name)\n",
    "\n",
    "    group_boundaries.append(len(ch_mapping_hbo[\"Right Prefrontal\"]) + group_boundaries[-1])\n",
    "\n",
    "    # find the channels that have 'S27_', 'S28_', 'S29_', 'S30_' in them\n",
    "    for ch_name in [ch_name for ch_name in ch_names_hbo if 'S27_' in ch_name or 'S28_' in ch_name or 'S29_' in ch_name or 'S30_' in ch_name]:\n",
    "        ch_mapping_hbo[\"Left Parietal\"].append(ch_name)\n",
    "\n",
    "    group_boundaries.append(len(ch_mapping_hbo[\"Left Parietal\"]) + group_boundaries[-1])\n",
    "\n",
    "    # find the channels that have 'S17_', 'S18_', 'S19_', 'S20_' in them\n",
    "    for ch_name in [ch_name for ch_name in ch_names_hbo if 'S17_' in ch_name or 'S18_' in ch_name or 'S19_' in ch_name or 'S20_' in ch_name]:\n",
    "        ch_mapping_hbo[\"Right Parietal\"].append(ch_name)\n",
    "\n",
    "    group_boundaries.append(len(ch_mapping_hbo[\"Right Parietal\"]) + group_boundaries[-1])\n",
    "\n",
    "    ch_mapping_hbo[\"Left Occipital\"].append('S21_D13 hbo')\n",
    "\n",
    "    ch_mapping_hbo[\"Left Occipital\"].append('S21_D16 hbo')\n",
    "\n",
    "    ch_mapping_hbo[\"Left Occipital\"].append('S23_D15 hbo')\n",
    "\n",
    "    # find the channels that have 'S32_', 'S31_' in them\n",
    "    for ch_name in [ch_name for ch_name in ch_names_hbo if 'S32_' in ch_name or 'S31_' in ch_name]:\n",
    "        ch_mapping_hbo[\"Left Occipital\"].append(ch_name)\n",
    "\n",
    "    group_boundaries.append(len(ch_mapping_hbo[\"Left Occipital\"]) + group_boundaries[-1])\n",
    "\n",
    "    ch_mapping_hbo[\"Right Occipital\"].append('S23_D16 hbo')\n",
    "\n",
    "    ch_mapping_hbo[\"Right Occipital\"].append('S21_D28 hbo')\n",
    "\n",
    "    ch_mapping_hbo[\"Right Occipital\"].append('S23_D30 hbo')\n",
    "\n",
    "    # find the channels that have 'S22_', 'S24_' in them\n",
    "    for ch_name in [ch_name for ch_name in ch_names_hbo if 'S22_' in ch_name or 'S24_' in ch_name]:\n",
    "        ch_mapping_hbo[\"Right Occipital\"].append(ch_name)\n",
    "\n",
    "    ch_mapping_hbr = {region: [channel.replace('hbo', 'hbr') for channel in ch_mapping_hbo[region]] for region in ch_mapping_hbo}\n",
    "\n",
    "    ch_mapping_hbt = {region: [channel.replace('hbo', 'hbt') for channel in ch_mapping_hbo[region]] for region in ch_mapping_hbo}\n",
    "\n",
    "    ch_mapping_all = {region: ch_mapping_hbo[region] + ch_mapping_hbr[region] + ch_mapping_hbt[region] for region in ch_mapping_hbo}\n",
    "\n",
    "    # concatenate the values of the dictionary into a list\n",
    "    all_channels_hbo = [channel for region in ch_mapping_hbo.values() for channel in region]\n",
    "\n",
    "    # duplicate all_channels but replace 'hbo' with 'hbr'\n",
    "    all_channels_hbr = [channel.replace('hbo', 'hbr') for channel in all_channels_hbo]\n",
    "\n",
    "    all_channels_hbt = [channel.replace('hbo', 'hbt') for channel in all_channels_hbo]\n",
    "\n",
    "    # concatenate all_channels_hbo and all_channels_hbr\n",
    "    all_channels = all_channels_hbo + all_channels_hbr + all_channels_hbt\n",
    "\n",
    "    # make a dictionary called ch_mapping_names that has the channel names without the 'hbo' or 'hbr' at the end\n",
    "    ch_mapping_names = {region: [channel[:-4] for channel in ch_mapping_hbo[region]] for region in ch_mapping_hbo}\n",
    "\n",
    "    # make a list of all the channel names without the 'hbo' or 'hbr' at the end\n",
    "    all_channels_names = [channel[:-4] for channel in all_channels_hbo]\n",
    "\n",
    "    ch_names_original = [ch_name[:-4] for ch_name in ch_names_hbo]\n",
    "\n",
    "    # Collect all new variables into a dictionary\n",
    "    mappings = {\n",
    "        \"ch_names_hbo\": ch_names_hbo,\n",
    "        \"ch_mapping_hbo\": ch_mapping_hbo,\n",
    "        \"ch_mapping_hbr\": ch_mapping_hbr,\n",
    "        \"ch_mapping_hbt\": ch_mapping_hbt,\n",
    "        \"ch_mapping_all\": ch_mapping_all,\n",
    "        \"all_channels_hbo\": all_channels_hbo,\n",
    "        \"all_channels_hbr\": all_channels_hbr,\n",
    "        \"all_channels_hbt\": all_channels_hbt,\n",
    "        \"all_channels\": all_channels,\n",
    "        \"ch_mapping_names\": ch_mapping_names,\n",
    "        \"all_channels_names\": all_channels_names,\n",
    "        \"ch_names_original\": ch_names_original,\n",
    "        \"group_boundaries\": group_boundaries\n",
    "    }\n",
    "\n",
    "    # Save the dictionary to a JSON file\n",
    "    with open(\"processed_data//mappings/mappings.json\", \"w\") as json_file:\n",
    "        json.dump(mappings, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalp Coupling Index (SCI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_full_sci:\n",
    "    raw_ods = load_data('raw_ods') if len(raw_ods) == 0 else raw_ods\n",
    "\n",
    "    # for each recording, count the number of channels with a sci greater than good_threshold\n",
    "    good_channels = [sum(scalp_coupling_index(raw_od, verbose=False) >= sci_threshold) for raw_od in raw_ods]\n",
    "    bad_channels = [sum(scalp_coupling_index(raw_od, verbose=False) < sci_threshold) for raw_od in raw_ods]\n",
    "    good_recordings = sum([good_channel >= good_threshold * (good_channel + bad_channel) for good_channel, bad_channel in zip(good_channels, bad_channels)])\n",
    "\n",
    "    # Plot the good vs bad channels for each recording in a dual bar chart\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar(range(len(good_channels)), good_channels, label='Good Channels')\n",
    "    ax.bar(range(len(bad_channels)), bad_channels, bottom=good_channels, label='Bad Channels')\n",
    "    ax.set_xlabel('Recording')\n",
    "    ax.set_ylabel('Number of Channels')\n",
    "    ax.axhline(raw_ods[0].info['nchan'] * good_threshold, color='green', linestyle='--')\n",
    "    title = f'Good vs Bad Channels (T = {sci_threshold})\\nGood Recordings: {good_recordings}, N = {len(raw_ods)}, Retention Rate: {good_recordings / len(raw_ods) * 100:.2f}%'\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    plt.savefig(f'plots/signal quality/Signal Quality (SCI).png', dpi=dpi)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient of Variance (CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_full_cv:\n",
    "    raws = load_data('raws') if len(raws) == 0 else raws\n",
    "\n",
    "    # for each recording, count the number of channels with a cv less than cov_threshold\n",
    "    good_channels = [sum(100 * np.std(ch) / np.mean(ch) < cv_threshold for ch in get_long_channels(raw).get_data()) for raw in raws]\n",
    "    bad_channels = [sum(100 * np.std(ch) / np.mean(ch) >= cv_threshold for ch in get_long_channels(raw).get_data()) for raw in raws]\n",
    "    good_recordings = sum([good_channel >= good_threshold * (good_channel + bad_channel) for good_channel, bad_channel in zip(good_channels, bad_channels)])\n",
    "\n",
    "    # Plot the good vs bad channels for each recording in a dual bar chart\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar(range(len(good_channels)), good_channels, label='Good Channels')\n",
    "    ax.bar(range(len(bad_channels)), bad_channels, bottom=good_channels, label='Bad Channels')\n",
    "    ax.set_xlabel('Recording')\n",
    "    ax.set_ylabel('Number of Channels')\n",
    "    ax.axhline(raws[0].info['nchan'] * good_threshold, color='green', linestyle='--')\n",
    "    title = f'Good vs Bad Channels (T = {cv_threshold})\\nGood Recordings: {good_recordings}, N = {len(raws)}, Retention Rate: {good_recordings / len(raws) * 100:.2f}%'\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    plt.savefig(f'plots/signal quality/Signal Quality (CV).png', dpi=dpi)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Peak Power/SCI Sliding Window CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_peak_power_sci_df:\n",
    "    raw_ods = load_data('raw_ods') if len(raw_ods) == 0 else raw_ods\n",
    "\n",
    "    peak_power_df = pd.DataFrame()\n",
    "    sci_df = pd.DataFrame()\n",
    "    for i, raw_od in enumerate(raw_ods, 1):\n",
    "        raw_od_annotated_pp, scores_pp, times_pp = peak_power(raw_od, time_window=5, verbose=False)\n",
    "        raw_od_annotated_sci, scores_sci, times_sci = scalp_coupling_index_windowed(raw_od, time_window=5, verbose=False)\n",
    "\n",
    "        # Convert scores and times to a DataFrame\n",
    "        df_pp = pd.DataFrame(scores_pp.T, columns=[ch_name for ch_name in raw_od.ch_names])\n",
    "        df_sci = pd.DataFrame(scores_sci.T, columns=[ch_name for ch_name in raw_od.ch_names])\n",
    "\n",
    "        # Add time window information\n",
    "        df_pp[\"Start_Time\"] = [t[0] for t in times_pp]\n",
    "        df_pp[\"End_Time\"] = [t[1] for t in times_pp]\n",
    "        df_sci[\"Start_Time\"] = [t[0] for t in times_sci]\n",
    "        df_sci[\"End_Time\"] = [t[1] for t in times_sci]\n",
    "\n",
    "        # Add an index column for window number\n",
    "        df_pp.insert(0, 'Window', range(1, len(df_pp) + 1))\n",
    "        df_sci.insert(0, 'Window', range(1, len(df_sci) + 1))\n",
    "\n",
    "        # Reorder columns so time comes first\n",
    "        df_pp = df_pp[[\"Start_Time\", \"End_Time\"] + list(df_pp.columns[:-2])]\n",
    "        df_sci = df_sci[[\"Start_Time\", \"End_Time\"] + list(df_sci.columns[:-2])]\n",
    "\n",
    "        # remove the columns with '850' in the name\n",
    "        df_pp = df_pp.loc[:, ~df_pp.columns.str.contains('850')]\n",
    "        df_sci = df_sci.loc[:, ~df_sci.columns.str.contains('850')]\n",
    "\n",
    "        # rename the columns to remove the ' 760' at the end if it exists\n",
    "        df_pp.columns = [col[:-4] if col.endswith(' 760') else col for col in df_pp.columns]\n",
    "        df_sci.columns = [col[:-4] if col.endswith(' 760') else col for col in df_sci.columns]\n",
    "\n",
    "        # Add a column for participant number, make it the first column\n",
    "        df_pp.insert(0, 'Participant', i)\n",
    "        df_sci.insert(0, 'Participant', i)\n",
    "\n",
    "        # Append the DataFrame to the list\n",
    "        peak_power_df = pd.concat([peak_power_df, df_pp])\n",
    "        sci_df = pd.concat([sci_df, df_sci])\n",
    "\n",
    "    # reset the index\n",
    "    peak_power_df.reset_index(drop=True, inplace=True)\n",
    "    sci_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    peak_power_df.to_csv('processed_data/windows/peak_power.csv', index=False)\n",
    "    sci_df.to_csv('processed_data/windows/sci.csv', index=False)\n",
    "\n",
    "# Load the DataFrame\n",
    "peak_power_df = pd.read_csv('processed_data/windows/peak_power.csv')\n",
    "sci_df = pd.read_csv('processed_data/windows/sci.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak Power/SCI Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_good_windows_plot:\n",
    "    # Compute the proportion of windows with peak power > peak_power_threshold for each channel\n",
    "    percentage_good_windows_peak_power_df = (\n",
    "        peak_power_df.groupby(\"Participant\")[peak_power_df.columns[4:]]\n",
    "        .apply(lambda df: (df > peak_power_threshold).sum() / len(df))\n",
    "    )\n",
    "\n",
    "    # add a good recordings column\n",
    "    good_recordings = (percentage_good_windows_peak_power_df > good_threshold).sum(axis=1) / len(percentage_good_windows_peak_power_df.columns)\n",
    "    percentage_good_windows_peak_power_df.insert(0, f'Good Recordings (peak_power > {peak_power_threshold} for > {good_threshold * 100}% of channels)', good_recordings)\n",
    "\n",
    "    # Compute the proportion of windows with SCI > good_threshold for each channel\n",
    "    percentage_good_windows_sci_df = (\n",
    "        sci_df.groupby(\"Participant\")[sci_df.columns[4:]]\n",
    "        .apply(lambda df: (df > sci_threshold).sum() / len(df))\n",
    "    )\n",
    "\n",
    "    # add a good recordings column\n",
    "    good_recordings = (percentage_good_windows_sci_df > good_threshold).sum(axis=1) / len(percentage_good_windows_sci_df.columns)\n",
    "    percentage_good_windows_sci_df.insert(0, f'Good Recordings (SCI > {sci_threshold} for > {good_threshold * 100}% of channels)', good_recordings)\n",
    "\n",
    "    # merge the two dataframes on the first 2 columns\n",
    "    percentage_good_windows_df = pd.merge(percentage_good_windows_peak_power_df[percentage_good_windows_peak_power_df.columns[:1]], percentage_good_windows_sci_df[percentage_good_windows_sci_df.columns[:1]], on='Participant')\n",
    "\n",
    "    # create a new column that is true if both columns are greater than good_threshold\n",
    "    percentage_good_windows_df['Good Recording'] = (percentage_good_windows_df.iloc[:, 0] > good_threshold) & (percentage_good_windows_df.iloc[:, 1] > good_threshold)\n",
    "\n",
    "    # save the dataframe to a csv file\n",
    "    percentage_good_windows_df.to_csv('processed_data/windows/percentage_good_windows.csv', index=False)\n",
    "\n",
    "    # Plot a bar chart where only the SCI windows are shown for each participant\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    x = np.arange(len(percentage_good_windows_df))\n",
    "    ax.bar(x, percentage_good_windows_df.iloc[:, 1], label='SCI', color='#FF8C00')  # Darker orange\n",
    "    ax.axhline(good_threshold, color='green', linestyle='--')\n",
    "    ax.set_xlabel('Participant')\n",
    "    ax.set_ylabel('Percentage of Channels (%)')\n",
    "    ax.set_title(f'Percentage of Channels where SCI > ' + str(sci_threshold) + ' for > ' + str(good_threshold * 100) + f'% of windows\\nGood Recordings: {percentage_good_windows_df[\"Good Recording\"].sum()}/{len(percentage_good_windows_df)}, Retention Rate: {percentage_good_windows_df[\"Good Recording\"].sum() / len(percentage_good_windows_df) * 100:.2f}%')\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig(f'plots/signal quality/Percentage of Good Windows.png', dpi=dpi // 2)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak Power/SCI Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_slope_pp_sci_plot:\n",
    "    pp_channel_slopes = []\n",
    "    sci_channel_slopes = []\n",
    "    for pp_channel, sci_channel in zip(percentage_good_windows_peak_power_df.columns[4:], percentage_good_windows_sci_df.columns[4:]):\n",
    "        pp_slope = []\n",
    "        sci_slope = []\n",
    "        for participant in peak_power_df['Participant'].unique():\n",
    "            # get the data for the channel\n",
    "            pp_array = peak_power_df[peak_power_df['Participant'] == participant][pp_channel]\n",
    "            sci_array = sci_df[sci_df['Participant'] == participant][sci_channel]\n",
    "\n",
    "            # get a line of best fit for the data\n",
    "            x = np.arange(len(pp_array))\n",
    "            pp_m, pp_b = np.polyfit(x, pp_array, 1)\n",
    "            pp_slope.append(pp_m)\n",
    "\n",
    "            sci_m, sci_b = np.polyfit(x, sci_array, 1)\n",
    "            sci_slope.append(sci_m)\n",
    "        pp_channel_slopes.append((pp_channel, np.mean(pp_slope)))\n",
    "        sci_channel_slopes.append((sci_channel, np.mean(sci_slope)))\n",
    "\n",
    "    # plot the slopes\n",
    "    fig, ax = plt.subplots(figsize=(20, 6))\n",
    "    # sort the channels by slope\n",
    "    pp_channel_slopes.sort(key=lambda x: x[1])\n",
    "    sci_channel_slopes.sort(key=lambda x: x[1])\n",
    "    bar_width = 0.45\n",
    "    x = np.arange(len(pp_channel_slopes))\n",
    "    ax.bar(x, [slope for channel, slope in pp_channel_slopes], bar_width, label='Peak Power')\n",
    "    ax.bar(x + bar_width, [slope for channel, slope in sci_channel_slopes], bar_width, label='SCI')\n",
    "    ax.set_xlabel('Channel')\n",
    "    ax.set_ylabel('Slope')\n",
    "    ax.set_title('Slope of Peak Power and SCI over Time')\n",
    "    ax.set_xticks(x + bar_width / 2)\n",
    "    ax.set_xticklabels([channel for channel, slope in pp_channel_slopes])\n",
    "    ax.legend()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/signal quality/Slope of Peak Power and SCI over Time.png', dpi=dpi)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head Size vs. SCI Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_11268\\2914967535.py:24: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '60.96' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  percentage_good_windows_sci_df_with_head_size.loc[i, 'Head Size (cm)'] = head_size\n"
     ]
    }
   ],
   "source": [
    "if get_head_size_vs_sci_plot:\n",
    "    raw_haemos = load_data('raw_haemos') if len(raw_haemos) == 0 else raw_haemos\n",
    "\n",
    "    cap_size = 58\n",
    "    percentage_good_windows_sci_df_with_head_size = percentage_good_windows_sci_df.copy()\n",
    "\n",
    "    # add the head size to the percentage_good_windows_sci_df as the first column\n",
    "    if 'Head Size (cm)' not in percentage_good_windows_sci_df_with_head_size.columns:\n",
    "        percentage_good_windows_sci_df_with_head_size.insert(0, 'Head Size (cm)', cap_size)\n",
    "\n",
    "    no_head_size = []\n",
    "\n",
    "    for i, raw_haemo in enumerate(raw_haemos, 1):\n",
    "        # get the head size\n",
    "        head_size = get_info(raw_haemo)['remarks']\n",
    "        if head_size:\n",
    "            head_size = float(head_size) * 2.54\n",
    "        else:\n",
    "            # add the participant number to the no_head_size list\n",
    "            no_head_size.append(i)\n",
    "            continue\n",
    "        \n",
    "        # append the head_size to percentage_good_windows_sci_df\n",
    "        percentage_good_windows_sci_df_with_head_size.loc[i, 'Head Size (cm)'] = head_size\n",
    "\n",
    "    # remove the participants with no head size\n",
    "    percentage_good_windows_sci_df_with_head_size = percentage_good_windows_sci_df_with_head_size.drop(no_head_size)\n",
    "\n",
    "    # get the correlation between head size and the channels\n",
    "    correlations = []\n",
    "    for channel in percentage_good_windows_sci_df_with_head_size.columns[2:]:\n",
    "        correlation = percentage_good_windows_sci_df_with_head_size['Head Size (cm)'].corr(percentage_good_windows_sci_df_with_head_size[channel])\n",
    "        correlations.append((channel, correlation))\n",
    "\n",
    "    # get the correlation between head size and the second column\n",
    "    correlation = percentage_good_windows_sci_df_with_head_size['Head Size (cm)'].corr(percentage_good_windows_sci_df_with_head_size.iloc[:, 1])\n",
    "\n",
    "    # plot the correlations\n",
    "    fig, ax = plt.subplots(figsize=(20, 6))\n",
    "    # sort the channels by correlation\n",
    "    correlations.sort(key=lambda x: x[1])\n",
    "    bar_width = 0.45\n",
    "    x = np.arange(len(correlations))\n",
    "    ax.bar(x, [correlation for channel, correlation in correlations], bar_width)\n",
    "    ax.set_xlabel('Channel')\n",
    "    ax.set_ylabel('Correlation')\n",
    "    ax.set_title('Correlation between Head Size and SCI, Correlation with Good Recordings: ' + str(correlation) + ', N = ' + str(len(percentage_good_windows_sci_df_with_head_size)))\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([channel for channel, correlation in correlations])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/signal quality/Correlation between Head Size and SCI.png', dpi=dpi / 3)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average SCI per Channel across Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_across_participant_sci_plots:\n",
    "    # Load the percentage_good_windows_df\n",
    "    percentage_good_windows_df = pd.read_csv('processed_data/windows/percentage_good_windows.csv')\n",
    "\n",
    "    # get a list of participants in percentage_good_windows_sci_df where Good Recording is True\n",
    "    good_participants = percentage_good_windows_df[percentage_good_windows_df['Good Recording'] == True].index\n",
    "\n",
    "    # make a dataframe of the average sci for each channel\n",
    "    avg_sci_df = sci_df.groupby('Participant').mean().drop(columns=['Window', 'Start_Time', 'End_Time'])\n",
    "\n",
    "    # drop the participants that are not in good_participants\n",
    "    avg_sci_df_good = avg_sci_df.loc[good_participants]\n",
    "\n",
    "    # drop the participants that are in good_participants\n",
    "    avg_sci_df_bad = avg_sci_df.drop(index=good_participants)\n",
    "\n",
    "    # make a list of the dataframes\n",
    "    avg_sci_dfs = [avg_sci_df, avg_sci_df_good, avg_sci_df_bad]\n",
    "    df_names = ['All Participants', 'Good Participants', 'Bad Participants']\n",
    "    color_list = ['red', 'blue', 'green', 'purple', 'orange', 'brown', 'pink', 'gray']\n",
    "\n",
    "    for df, df_name in zip(avg_sci_dfs, df_names):\n",
    "\n",
    "        # make a violin plot of the average sci for each channel\n",
    "        fig, ax = plt.subplots(figsize=(35, 6))\n",
    "        parts = ax.violinplot(df, showmeans=False, widths=1, showextrema=False)\n",
    "\n",
    "        # match the violin plot colors to the columns in avg_sci_df to the channels in ch_mapping_names\n",
    "        color_i = 0\n",
    "        colors = []\n",
    "        region_labels = []\n",
    "\n",
    "        # for each region in ch_mapping_names, apply the color to the channels in that region\n",
    "        for region, channels in mappings['ch_mapping_names'].items():\n",
    "            for channel in channels:\n",
    "                if channel in df.columns:\n",
    "                    colors.append(color_list[color_i])\n",
    "                    region_labels.append(region)\n",
    "            color_i += 1\n",
    "\n",
    "        # set the colors of the violins\n",
    "        for i, pc in enumerate(parts['bodies']):\n",
    "            pc.set_facecolor(colors[i])\n",
    "            pc.set_edgecolor('black')\n",
    "            pc.set_alpha(1)\n",
    "\n",
    "        # create a legend\n",
    "        handles = [plt.Rectangle((0, 0), 1, 1, color=color) for color in list(dict.fromkeys(colors))]\n",
    "        ax.legend(handles, list(dict.fromkeys(region_labels)), loc='lower left')\n",
    "\n",
    "        # add a white scatter plot of the mean sci for each channel\n",
    "        ax.scatter(np.arange(1, len(df.columns) + 1), df.mean(), color='white', zorder=3)\n",
    "\n",
    "        ax.set_xlabel('Channel')\n",
    "        ax.set_ylabel('Average SCI')\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.axhline(good_threshold, color='green', linestyle='--')\n",
    "        ax.set_title(f'Average SCI per Channel: ({df_name}), N = {len(df)}')\n",
    "        ax.set_xticks(np.arange(1, len(df.columns) + 1))\n",
    "        ax.set_xticklabels(df.columns)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'plots/signal quality/Average SCI (Windowed) per Channel/{df_name}.png', dpi=dpi / 3)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Epoch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_epoch_data:\n",
    "    raw_haemo_good_recordings = load_data('raw_haemos', 'good') if len(raw_haemo_good_recordings) == 0 else raw_haemo_good_recordings\n",
    "\n",
    "    modes = ['all', 'face_type', 'emotion', 'face_type_emotion']\n",
    "    conditions_list = {\n",
    "        'all': ['Base', 'Blck'],\n",
    "        'face_type': ['Real', 'Virt'],\n",
    "        'emotion': ['Joy', 'Fear', 'Anger', 'Disgust', 'Sadness', 'Neutral', 'Surprise'],\n",
    "        'face_type_emotion': ['Real_Joy', 'Real_Fear', 'Real_Anger', 'Real_Disgust', 'Real_Sadness', 'Real_Neutral', 'Real_Surprise',\n",
    "                              'Virt_Joy', 'Virt_Fear', 'Virt_Anger', 'Virt_Disgust', 'Virt_Sadness', 'Virt_Neutral', 'Virt_Surprise']\n",
    "    }\n",
    "\n",
    "    for mode in modes:\n",
    "        epochs = get_epochs(raw_haemo_good_recordings, mode, max_times, 'epochs')\n",
    "        for condition in conditions_list[mode]:\n",
    "            # get the epochs for each condition\n",
    "            epochs_condition = epochs[condition]\n",
    "\n",
    "            # save the epochs to a file\n",
    "            np.save(f'processed_data/epochs/{mode}_{condition}_epochs.npy', epochs_condition)\n",
    "\n",
    "# We now have epochs[mode][condition].shape = (n_participants, n_epochs, n_channel_types, n_channels, n_times)\n",
    "epochs = {\n",
    "    mode: {\n",
    "        condition: np.load(f'processed_data/epochs/{mode}_{condition}_epochs.npy')\n",
    "        for condition in conditions_list[mode]\n",
    "    }\n",
    "    for mode in modes\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Design Matrix Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nilearn\\glm\\first_level\\experimental_paradigm.py:113: FutureWarning: The provided callable <function sum at 0x00000210015F54E0> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  COLUMN_DEFINING_EVENT_IDENTITY, sort=False).agg(STRATEGY).reset_index()\n"
     ]
    }
   ],
   "source": [
    "modes = ['face_type']\n",
    "conditions_list = {\n",
    "    'face_type': ['Real', 'Virt']\n",
    "}\n",
    "channel_types = ['hbo', 'hbr', 'hbt']\n",
    "\n",
    "if get_glm_design_matrix_plot:\n",
    "    raw_haemo_good_recordings = load_data('raw_haemos', 'good') if len(raw_haemo_good_recordings) == 0 else raw_haemo_good_recordings\n",
    "    for mode in modes:\n",
    "        raw_haemos_annotated = get_epochs(raw_haemo_good_recordings, mode, max_times, 'annotated')\n",
    "        for i, raw_haemo in enumerate(raw_haemos_annotated, 1):\n",
    "            if i == 36:\n",
    "                break\n",
    "            elif i < 35:\n",
    "                continue\n",
    "            raw_haemo_annots = pick_channels(raw_haemo, channel_types)\n",
    "\n",
    "            # Create events for nilearn\n",
    "            conditions = raw_haemo_annots.annotations.description\n",
    "            onsets = raw_haemo_annots.annotations.onset - raw_haemo_annots.first_time\n",
    "            duration = raw_haemo_annots.annotations.duration\n",
    "            events = pd.DataFrame(\n",
    "                {\"trial_type\": conditions, \"onset\": onsets, \"duration\": duration}\n",
    "            )\n",
    "\n",
    "            design_matrix = make_first_level_design_matrix(\n",
    "                raw_haemo_annots.times,\n",
    "                events,\n",
    "                drift_model=\"cosine\",\n",
    "                hrf_model=\"spm\",\n",
    "                high_pass=0.03125,  # The cutoff period (1/high_pass) should be set as the longest period between two trials of the same condition multiplied by 2\n",
    "            )\n",
    "\n",
    "    # Create a mask for the design matrix\n",
    "    design_matrix = design_matrix.loc[:, design_matrix.columns.str.contains(\"Real|Virt\")]\n",
    "\n",
    "    # only keep the first 250 seconds of the design matrix\n",
    "    design_matrix = design_matrix.iloc[:int(250 * raw_haemo_annots.info['sfreq']), :]\n",
    "        \n",
    "    # plot the design matrix\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    design_matrix.plot(ax=ax, legend=True, linewidth=4, alpha=1)\n",
    "    plt.xlabel(\"Time (s)\", fontsize=18)\n",
    "    plt.ylabel(\"Amplitude (AU)\", fontsize=18)\n",
    "    plt.title(f\"Sample Design Matrix for Participant, First 250s\", fontsize=24)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig(f\"plots/figures/Sample Design Matrix.png\", dpi=dpi // 2)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run GLM Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = ['all', 'face_type', 'emotion', 'face_type_emotion']\n",
    "conditions_list = {\n",
    "    'all': ['Blck', 'Base'],\n",
    "    'face_type': ['Real', 'Virt'],\n",
    "    'emotion': ['Joy', 'Fear', 'Anger', 'Disgust', 'Sadness', 'Neutral', 'Surprise'],\n",
    "    'face_type_emotion': ['Real_Joy', 'Real_Fear', 'Real_Anger', 'Real_Disgust', 'Real_Sadness', 'Real_Neutral', 'Real_Surprise',\n",
    "                          'Virt_Joy', 'Virt_Fear', 'Virt_Anger', 'Virt_Disgust', 'Virt_Sadness', 'Virt_Neutral', 'Virt_Surprise']\n",
    "}\n",
    "channel_types = ['hbo', 'hbr', 'hbt']\n",
    "\n",
    "if get_glm_analysis:\n",
    "    raw_haemo_good_recordings = load_data('raw_haemos', 'good') if len(raw_haemo_good_recordings) == 0 else raw_haemo_good_recordings\n",
    "    for mode in modes:\n",
    "        cha_df = pd.DataFrame()\n",
    "        roi_df = pd.DataFrame()\n",
    "        con_df = pd.DataFrame()\n",
    "        raw_haemos_annotated = get_epochs(raw_haemo_good_recordings, mode, max_times, 'annotated')\n",
    "        for i, raw_haemo in enumerate(raw_haemos_annotated, 1):\n",
    "            raw_haemo_annots = pick_channels(raw_haemo, channel_types)\n",
    "\n",
    "            # Create events for nilearn\n",
    "            conditions = raw_haemo_annots.annotations.description\n",
    "            onsets = raw_haemo_annots.annotations.onset - raw_haemo_annots.first_time\n",
    "            duration = raw_haemo_annots.annotations.duration\n",
    "            events = pd.DataFrame(\n",
    "                {\"trial_type\": conditions, \"onset\": onsets, \"duration\": duration}\n",
    "            )\n",
    "\n",
    "            design_matrix = make_first_level_design_matrix(\n",
    "                raw_haemo_annots.times,\n",
    "                events,\n",
    "                drift_model=\"cosine\",\n",
    "                hrf_model=\"spm\",\n",
    "                high_pass=0.03125,  # The cutoff period (1/high_pass) should be set as the longest period between two trials of the same condition multiplied by 2\n",
    "            )\n",
    "            \n",
    "            # Run GLM\n",
    "            glm_est = run_glm(raw_haemo_annots, design_matrix, n_jobs=n_jobs)\n",
    "\n",
    "            cha = glm_est.to_dataframe()\n",
    "\n",
    "            # in ch_mapping_all, for each list of channels in the dict, each string is formatted as 'S{number}_D{number} {hbo/hbr}', extract the number from the string and replace the string with [number, number]\n",
    "            groups = {region: [[int(re.findall(r'\\d+', channel)[0]), int(re.findall(r'\\d+', channel)[1])] for channel in mappings['ch_mapping_all'][region]] for region in mappings['ch_mapping_all']}\n",
    "            # apply picks_pair_to_idx to each region in groups\n",
    "            for region in groups:\n",
    "                groups[region] = picks_pair_to_idx(raw_haemo_annots, groups[region], on_missing='ignore')\n",
    "\n",
    "            # Compute region of interest results from channel data\n",
    "            roi = glm_est.to_dataframe_region_of_interest(\n",
    "                groups, design_matrix.columns, demographic_info=True\n",
    "            )\n",
    "\n",
    "            # Define contrasts\n",
    "            contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "            basic_conts = dict(\n",
    "                [(column, contrast_matrix[j]) for j, column in enumerate(design_matrix.columns)]\n",
    "            )\n",
    "            contrasts = []\n",
    "            unique_annots = np.unique(raw_haemo_annots.annotations.description).tolist()\n",
    "            pairs = list(itertools.combinations(unique_annots, 2))\n",
    "            # include the opposite of each pair\n",
    "            pairs = pairs + [(pair[1], pair[0]) for pair in pairs]\n",
    "\n",
    "            # Compute defined contrast pairs\n",
    "            for pair in pairs:\n",
    "                con = glm_est.compute_contrast(basic_conts[pair[0]] - basic_conts[pair[1]]).to_dataframe()\n",
    "                con[\"contrast_pair\"] = f\"{pair[0]} - {pair[1]}\"\n",
    "                contrasts.append(con)\n",
    "\n",
    "            # Add the participant ID to the dataframes\n",
    "            roi[\"Participant\"] = cha[\"Participant\"] = i\n",
    "            for con in contrasts:\n",
    "                con[\"Participant\"] = i\n",
    "\n",
    "            # Convert to uM for nicer plotting below.\n",
    "            cha[\"theta\"] = [t * 1.0e6 for t in cha[\"theta\"]]\n",
    "            roi[\"theta\"] = [t * 1.0e6 for t in roi[\"theta\"]]\n",
    "            for con in contrasts:\n",
    "                con[\"effect\"] = [t * 1.0e6 for t in con[\"effect\"]]\n",
    "\n",
    "            # Append the dataframes to the main dataframes\n",
    "            cha_df = pd.concat([cha_df, cha])\n",
    "            roi_df = pd.concat([roi_df, roi])\n",
    "            for con in contrasts:\n",
    "                con_df = pd.concat([con_df, con])\n",
    "\n",
    "        # Apply FDR correction to all dataframes\n",
    "        for df in [cha_df, roi_df, con_df]:\n",
    "            if 'p_value' in df.columns:\n",
    "                _, df['p_value_fdr'] = fdrcorrection(df['p_value'])\n",
    "\n",
    "        cha_df.to_csv('processed_data/glm/cha/cha_df_' + mode + '.csv', index=False)\n",
    "        roi_df.to_csv('processed_data/glm/roi/roi_df_' + mode + '.csv', index=False)\n",
    "        con_df.to_csv('processed_data/glm/cons/con_df_' + mode + '.csv', index=False)\n",
    "\n",
    "# load the dataframes\n",
    "glm = {\n",
    "    mode: {\n",
    "        'cha': pd.read_csv(f'processed_data/glm/cha/cha_df_{mode}.csv'),\n",
    "        'roi': pd.read_csv(f'processed_data/glm/roi/roi_df_{mode}.csv'),\n",
    "        'con': pd.read_csv(f'processed_data/glm/cons/con_df_{mode}.csv')\n",
    "    }\n",
    "    for mode in modes\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual GLM Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_ind_glm_plots:\n",
    "    channel_type = ['hbt']\n",
    "    for mode in modes:\n",
    "        grp_results = glm[mode]['roi'].query(f\"Condition in {conditions_list[mode]}\")\n",
    "        grp_results = grp_results.query(f\"Chroma in {channel_type}\")\n",
    "\n",
    "        theta_min = grp_results['theta'].min()\n",
    "        theta_max = grp_results['theta'].max()\n",
    "\n",
    "        # clear any files in the plots/glm/individual folder\n",
    "        for f in os.listdir('plots/glm/individual_' + mode):\n",
    "            os.remove(os.path.join('plots/glm/individual_' + mode, f))\n",
    "\n",
    "        for i in grp_results['Participant'].unique():\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            fig.suptitle(f'GLM Results for Participant {i}')\n",
    "\n",
    "            sns.swarmplot(data=grp_results.query(f\"Participant == {i} and Chroma == '{channel_type[0]}'\"),\n",
    "                  x='Condition', y='theta', hue='ROI', ax=ax, dodge=False)\n",
    "            ax.set_title(f'{channel_type[0]}')\n",
    "            ax.set_ylabel('Theta (uM)')\n",
    "            ax.set_ylim(theta_min, theta_max)\n",
    "            ax.set_xlabel('Condition')\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "            plt.savefig(f'plots/glm/individual_{mode}/Participant {i}.png', dpi=dpi / 4)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group GLM Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_group_glm_plots:\n",
    "    channel_type = ['hbt']\n",
    "    for mode in modes:\n",
    "        grp_results = glm[mode]['roi'].query(f\"Condition in {conditions_list[mode]}\")\n",
    "        grp_results = grp_results.query(f\"Chroma in {channel_type}\")\n",
    "\n",
    "        # Run a GLM model\n",
    "        roi_model = mixedlm(\"theta ~ -1 + ROI:Condition:Chroma\", grp_results, groups=grp_results[\"Participant\"]).fit(method=\"nm\")\n",
    "\n",
    "        # Get the results of the model and put it in a csv file\n",
    "        roi_model_results = statsmodels_to_results(roi_model)\n",
    "\n",
    "        # Apply FDR correction to the p-values in roi_model_results\n",
    "        _, roi_model_results['P>|z|_fdr'] = fdrcorrection(roi_model_results['P>|z|'])\n",
    "\n",
    "        # plot the results of the model for 'hbt' channel type\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        fig.suptitle(f'GLM Results for Group - {mode}')\n",
    "\n",
    "        sns.swarmplot(data=roi_model_results.query(f\"Chroma == '{channel_type[0]}'\"),\n",
    "              x='Condition', y='Coef.', hue='ROI', ax=ax, dodge=False)\n",
    "        ax.set_title(f'{channel_type[0]}')\n",
    "        ax.set_ylabel('Theta (uM)')\n",
    "        ax.set_xlabel('Condition')\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f'plots/glm/group_results/results_{mode}.png', dpi=dpi / 4)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_group_contrast_plots:\n",
    "    channel_type = 'hbt'\n",
    "    for mode in modes:\n",
    "        pairs = list(itertools.combinations(conditions_list[mode], 2))\n",
    "        for pair in pairs:\n",
    "            con_summary = glm[mode]['con'].query(f\"contrast_pair == '{pair[0]} - {pair[1]}'\")\n",
    "\n",
    "            if len(con_summary) == 0:\n",
    "                print(f\"No data for contrast {pair[0]} - {pair[1]}\")\n",
    "                continue\n",
    "\n",
    "            raw_haemos = load_data('raw_haemos') if len(raw_haemos) == 0 else raw_haemos\n",
    "            raw_haemo = pick_channels(raw_haemos[0].copy(), 'hbo')\n",
    "            raw_haemo_chs = pick_channels(raw_haemos[0].copy(), channel_type).ch_names\n",
    "\n",
    "            con_summary_channel = con_summary.query(f\"Chroma in {[channel_type]}\")\n",
    "\n",
    "            # Run group level model and convert to dataframe\n",
    "            con_model = mixedlm(\"effect ~ -1 + ch_name:Chroma\", con_summary_channel, groups=con_summary_channel[\"Participant\"]).fit(method=\"nm\")\n",
    "\n",
    "            # Get the results of the model\n",
    "            con_model_df = statsmodels_to_results(con_model, raw_haemo_chs)\n",
    "            \n",
    "            # Apply FDR correction to the group-level p-values from the model\n",
    "            _, con_model_df['p_value_fdr'] = fdrcorrection(con_model_df['P>|z|'])\n",
    "\n",
    "            # Plot the topographic map\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(10, 6))\n",
    "            fig.suptitle(f'Contrast: {pair[0]} > {pair[1]}', fontsize=24, x=0.4)\n",
    "\n",
    "            # set the \"Coef.\" value to near 0 for channels that are not significant\n",
    "            coef = con_model_df.copy()\n",
    "            coef.loc[coef['p_value_fdr'] > 0.05, 'Coef.'] /= 15\n",
    "\n",
    "            norm = mpl.colors.Normalize(vmin=-3, vmax=3)\n",
    "\n",
    "            # plot the topomap\n",
    "            mne.viz.plot_topomap(coef[\"Coef.\"].to_numpy(), raw_haemo.info, extrapolate='head', show=False, axes=axes[0], sensors='ok', cnorm=norm)\n",
    "\n",
    "            # make a plot of a colorbar without using plt.colorbar\n",
    "            cb1 = mpl.colorbar.ColorbarBase(axes[1], cmap=mpl.cm.RdBu_r, norm=norm, orientation='vertical')\n",
    "            cb1.set_label('Coefficient', fontsize=16)\n",
    "            cb1.ax.set_aspect(3)\n",
    "\n",
    "            # make the colorbar numbers larger\n",
    "            for label in cb1.ax.get_yticklabels():\n",
    "                label.set_fontsize(16)\n",
    "\n",
    "            plt.tight_layout(pad=0, rect=[0, 0, 1, 0.95])\n",
    "            plt.subplots_adjust(wspace=-0.5)\n",
    "\n",
    "            if \"Neutral\" in pair:\n",
    "                plt.savefig(f'plots/glm/contrasts/differences_neutral/Contrast_{pair[0]}-{pair[1]}.png', dpi=dpi / 2)\n",
    "            else:\n",
    "                plt.savefig(f'plots/glm/contrasts/differences/Contrast_{pair[0]}-{pair[1]}.png', dpi=dpi / 2)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significant Group Contrast Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_31308\\1331308252.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n"
     ]
    }
   ],
   "source": [
    "if get_sig_group_contrast_table:\n",
    "    all_significant_contrasts = pd.DataFrame()\n",
    "\n",
    "    # pick channel type\n",
    "    channel_type = 'hbt'\n",
    "\n",
    "    for mode in modes:\n",
    "        if mode == 'all':\n",
    "            continue\n",
    "        pairs = list(itertools.combinations(conditions_list[mode], 2))\n",
    "        for pair in pairs:\n",
    "            con_summary = glm[mode]['con'].query(f\"contrast_pair == '{pair[0]} - {pair[1]}'\")\n",
    "\n",
    "            if len(con_summary) == 0:\n",
    "                print(f\"No data for contrast {pair[0]} - {pair[1]}\")\n",
    "                continue\n",
    "\n",
    "            raw_haemos = load_data('raw_haemos') if len(raw_haemos) == 0 else raw_haemos\n",
    "            raw_haemo = pick_channels(raw_haemos[0].copy(), 'hbo')\n",
    "            raw_haemo_chs = pick_channels(raw_haemos[0].copy(), channel_type).ch_names\n",
    "\n",
    "            con_summary_channel = con_summary.query(f\"Chroma in {[channel_type]}\")\n",
    "\n",
    "            # Run group level model and convert to dataframe\n",
    "            con_model = mixedlm(\"effect ~ -1 + ch_name:Chroma\", con_summary_channel, groups=con_summary_channel[\"Participant\"]).fit(method=\"nm\")\n",
    "\n",
    "            # Get the results of the model\n",
    "            con_model_df = statsmodels_to_results(con_model, raw_haemo_chs)\n",
    "\n",
    "            # Apply FDR correction to the group-level p-values from the model\n",
    "            _, con_model_df['p_value_fdr'] = fdrcorrection(con_model_df['P>|z|'])\n",
    "\n",
    "            # Add a column for the contrast pair\n",
    "            con_model_df['contrast_pair'] = f\"{pair[0]} > {pair[1]}\"\n",
    "\n",
    "            con_model_df['mode'] = mode\n",
    "\n",
    "            # append the dataframe to the all_significant_contrasts dataframe\n",
    "            filtered_con_model_df = con_model_df[con_model_df['p_value_fdr'] < 0.05]\n",
    "            \n",
    "            all_significant_contrasts = pd.concat([all_significant_contrasts, filtered_con_model_df])\n",
    "\n",
    "            all_significant_contrasts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            # Create a new column that matches ch_name to mappings['ch_mapping_hbt'] by finding the key in the dictionary\n",
    "            all_significant_contrasts['Region'] = all_significant_contrasts['ch_name'].apply(lambda x: next((k for k, v in mappings['ch_mapping_hbt'].items() if x in v), None))\n",
    "\n",
    "    all_significant_contrasts.to_csv('processed_data/glm/all_significant_contrasts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI Timeseries Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_roi_timeseries_activity:\n",
    "    raw_haemo_good_recordings = load_data('raw_haemos', 'good') if len(raw_haemo_good_recordings) == 0 else raw_haemo_good_recordings\n",
    "    epoch_dfs = get_epochs(raw_haemo_good_recordings, 'face_type_emotion', max_times, 'data')\n",
    "\n",
    "    channel_types = ['hbo', 'hbr', 'hbt']\n",
    "\n",
    "    roi_timeseries_activity = pd.DataFrame()\n",
    "\n",
    "    onset_time = 4\n",
    "\n",
    "    for i in range(len(epoch_dfs)):\n",
    "        sex = epoch_dfs[i]['Sex'].unique()[0]\n",
    "        # remove the sex column from the dataframe\n",
    "        epoch_dfs[i] = epoch_dfs[i].drop(columns=['Sex'])\n",
    "\n",
    "        # add a column for the participant number, make it the first column\n",
    "        epoch_dfs[i].insert(0, 'Participant', i + 1)\n",
    "\n",
    "        # for every \"\" in the description, replace it with the previous non \"\" value\n",
    "        epoch_dfs[i]['description'] = epoch_dfs[i]['description'].replace('', np.nan).ffill()\n",
    "\n",
    "        # Rename the time column to 'Time'\n",
    "        epoch_dfs[i].rename(columns={'time': 'Time'}, inplace=True)\n",
    "\n",
    "        # Split the description into two columns, one for the face type and one for the emotion\n",
    "        epoch_dfs[i].insert(2, 'Face_type', epoch_dfs[i]['description'].str.split('_').str[0])\n",
    "        epoch_dfs[i].insert(3, 'Emotion', epoch_dfs[i]['description'].str.split('_').str[1])\n",
    "\n",
    "        # Remove the description column\n",
    "        epoch_dfs[i] = epoch_dfs[i].drop(columns=['description'])\n",
    "\n",
    "        # Initialize Epoch column in the 3rd position with NaN\n",
    "        epoch_dfs[i].insert(2, 'Epoch', np.nan)\n",
    "\n",
    "        # Assign epochs based on contiguous runs of (Face_type, Emotion) for non-Base/Task rows\n",
    "        epoch_counter = 0\n",
    "        is_nan = True\n",
    "\n",
    "        for idx, row in epoch_dfs[i].iterrows():\n",
    "            ft, emo = row['Face_type'], row['Emotion']\n",
    "            if ft in ['Base', 'Task']:\n",
    "                is_nan = True\n",
    "                continue\n",
    "            if pd.isna(emo):\n",
    "                is_nan = True\n",
    "                continue\n",
    "            if emo != np.nan and is_nan:\n",
    "                epoch_counter += 1\n",
    "                is_nan = False\n",
    "            # Assign epoch number to the current row\n",
    "            epoch_dfs[i].at[idx, 'Epoch'] = epoch_counter\n",
    "\n",
    "        # Remove the Emotion rows that are nan\n",
    "        epoch_dfs[i] = epoch_dfs[i][epoch_dfs[i]['Emotion'].notna()]\n",
    "\n",
    "        # get the min and max Time for each epoch and add the difference to a Duration column\n",
    "        epoch_dfs[i].insert(5, 'Duration', np.nan)\n",
    "        for epoch in epoch_dfs[i]['Epoch'].unique():\n",
    "            epoch_df = epoch_dfs[i][epoch_dfs[i]['Epoch'] == epoch]\n",
    "            min_time = epoch_df['Time'].min()\n",
    "            max_time = epoch_df['Time'].max()\n",
    "            duration = max_time - min_time\n",
    "            epoch_dfs[i].loc[epoch_dfs[i]['Epoch'] == epoch, 'Duration'] = duration\n",
    "\n",
    "        # remove the first onset_time seconds of each epoch by getting the time of the first index of each epoch and removing rows where that time + onset_time seconds is less than the Time column\n",
    "        for epoch in epoch_dfs[i]['Epoch'].unique():\n",
    "            epoch_df = epoch_dfs[i][epoch_dfs[i]['Epoch'] == epoch]\n",
    "            min_time = epoch_df['Time'].min()\n",
    "            epoch_dfs[i] = epoch_dfs[i][~((epoch_dfs[i]['Epoch'] == epoch) & (epoch_dfs[i]['Time'] < min_time + onset_time))]\n",
    "\n",
    "        # Remove the Time column\n",
    "        epoch_dfs[i] = epoch_dfs[i].drop(columns=['Time'])\n",
    "\n",
    "        # Average the data for each epoch\n",
    "        epoch_dfs[i] = epoch_dfs[i].groupby(['Participant', 'Epoch', 'Face_type', 'Emotion']).mean().reset_index()\n",
    "\n",
    "        if 'hbo' in channel_types:\n",
    "            for region, channels in mappings['ch_mapping_hbo'].items():\n",
    "                # Ensure the channels exist in the dataframe to avoid errors\n",
    "                valid_channels = [channel for channel in channels if channel in epoch_dfs[i].columns]\n",
    "                if valid_channels:\n",
    "                    # Create a new column for the region's average\n",
    "                    epoch_dfs[i][region + ' Average Hbo'] = epoch_dfs[i][valid_channels].mean(axis=1)\n",
    "\n",
    "        if 'hbr' in channel_types:\n",
    "            for region, channels in mappings['ch_mapping_hbr'].items():\n",
    "                # Ensure the channels exist in the dataframe to avoid errors\n",
    "                valid_channels = [channel for channel in channels if channel in epoch_dfs[i].columns]\n",
    "                if valid_channels:\n",
    "                    # Create a new column for the region's average\n",
    "                    epoch_dfs[i][region + ' Average Hbr'] = epoch_dfs[i][valid_channels].mean(axis=1)\n",
    "\n",
    "        if 'hbt' in channel_types:\n",
    "            for region, channels in mappings['ch_mapping_hbt'].items():\n",
    "                # Ensure the channels exist in the dataframe to avoid errors\n",
    "                valid_channels = [channel for channel in channels if channel in epoch_dfs[i].columns]\n",
    "                if valid_channels:\n",
    "                    # Create a new column for the region's average\n",
    "                    epoch_dfs[i][region + ' Average Hbt'] = epoch_dfs[i][valid_channels].mean(axis=1)\n",
    "\n",
    "        # drop all the channel columns\n",
    "        epoch_dfs[i].drop(columns=mappings['all_channels'], inplace=True)\n",
    "\n",
    "        # Add an empty column for repetition and put it after the Emotion column\n",
    "        epoch_dfs[i].insert(4, 'Repetition', np.nan)\n",
    "\n",
    "        conditions = defaultdict(int)\n",
    "        for index, row in epoch_dfs[i].iterrows():\n",
    "            # Add the Face_type-Emotion pair to the conditions dictionary and increment the count\n",
    "            conditions[f\"{row['Face_type']}-{row['Emotion']}\"] += 1\n",
    "\n",
    "            # Add the count to the Repetition column\n",
    "            epoch_dfs[i].at[index, 'Repetition'] = conditions[f\"{row['Face_type']}-{row['Emotion']}\"]\n",
    "\n",
    "        epoch_dfs[i].insert(5, 'Sex', sex)\n",
    "\n",
    "        # add the dataframe to the average_timeseries_activity datafram\n",
    "        roi_timeseries_activity = pd.concat([roi_timeseries_activity, epoch_dfs[i]])\n",
    "\n",
    "    # reset the index\n",
    "    roi_timeseries_activity.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # name the index column to 'observation'\n",
    "    roi_timeseries_activity.index.name = 'Observation'\n",
    "\n",
    "    # replace any spaces in the column names with underscores\n",
    "    roi_timeseries_activity.columns = roi_timeseries_activity.columns.str.replace(' ', '_')\n",
    "\n",
    "    # capitalize the column names\n",
    "    roi_timeseries_activity.columns = roi_timeseries_activity.columns.str.capitalize()\n",
    "\n",
    "    mappings_file = {}\n",
    "    for col in roi_timeseries_activity.select_dtypes(include=['object']).columns:\n",
    "        # Create a mapping dictionary for the column\n",
    "        unique_values = roi_timeseries_activity[col].unique()\n",
    "        col_mapping = {val: idx for idx, val in enumerate(unique_values)}\n",
    "        mappings_file[col] = col_mapping\n",
    "\n",
    "        # Replace the column values in the DataFrame with numeric values\n",
    "        roi_timeseries_activity[col] = roi_timeseries_activity[col].map(col_mapping)\n",
    "\n",
    "    # Save mappings to a JSON file\n",
    "    with open('processed_data/roi_timeseries_activity/mappings.json', 'w') as json_file:\n",
    "        json.dump(mappings_file, json_file, indent=4)\n",
    "\n",
    "    # Get the unique number of participants\n",
    "    num_participants = roi_timeseries_activity['Participant'].nunique()\n",
    "\n",
    "    # save the dataframe to a csv file\n",
    "    roi_timeseries_activity.to_csv(f'processed_data/roi_timeseries_activity/roi_timeseries_activity_sci{sci_threshold}_n{num_participants}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERP Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:41: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:44: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:86: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:87: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:90: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_28344\\2364478111.py:91: RuntimeWarning: Mean of empty slice\n",
      "  epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "source": [
    "modes = ['face_type', 'emotion', 'face_type_emotion']\n",
    "conditions_list = {\n",
    "    'face_type': ['Real', 'Virt'],\n",
    "    'emotion': ['Joy', 'Fear', 'Anger', 'Disgust', 'Sadness', 'Neutral', 'Surprise'],\n",
    "    'face_type_emotion': ['Real_Joy', 'Real_Fear', 'Real_Anger', 'Real_Disgust', 'Real_Sadness', 'Real_Neutral', 'Real_Surprise',\n",
    "                          'Virt_Joy', 'Virt_Fear', 'Virt_Anger', 'Virt_Disgust', 'Virt_Sadness', 'Virt_Neutral', 'Virt_Surprise']\n",
    "}\n",
    "channel_types = ['hbo', 'hbr', 'hbt']\n",
    "\n",
    "dict_channel_types = {\n",
    "    channel_type: idx for idx, channel_type in enumerate(channel_types)\n",
    "}\n",
    "\n",
    "if get_erp_plots:\n",
    "    # We now have epochs[mode][condition].shape = (n_participants, n_epochs, n_channel_types, n_channels, n_times)\n",
    "    epochs = {\n",
    "        mode: {\n",
    "            condition: np.load(f'processed_data/epochs/{mode}_{condition}_epochs.npy')\n",
    "            for condition in conditions_list[mode]\n",
    "        }\n",
    "        for mode in modes\n",
    "    }\n",
    "\n",
    "    # make a color list for the different channel types\n",
    "    colors = {\n",
    "        'hbo': 'red',\n",
    "        'hbr': 'blue',\n",
    "        'hbt': 'purple'\n",
    "    }\n",
    "\n",
    "    # pick a channel type to plot the difference between regions\n",
    "    difference_channel_type = 'hbt'\n",
    "\n",
    "    for mode in modes:\n",
    "        for condition in conditions_list[mode]:\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "            for channel_type in channel_types:\n",
    "                # get epoch data, shape is now (n_participants, n_times)\n",
    "                epoch_data = np.nanmean(epochs[mode][condition][:, :, dict_channel_types[channel_type]], axis=(1, 2))\n",
    "\n",
    "                # get the mean of the data\n",
    "                epoch_data_mean = np.nanmean(epoch_data, axis=0)\n",
    "                \n",
    "                # get the standard error of the mean\n",
    "                epoch_data_sem = np.nanstd(epoch_data, axis=0) / np.sqrt(epoch_data.shape[0])\n",
    "\n",
    "                # plot the mean\n",
    "                ax.plot(epoch_data_mean, label=channel_type, color=colors[channel_type])\n",
    "\n",
    "                # plot the standard error of the mean as a shaded area\n",
    "                ax.fill_between(np.arange(epoch_data_mean.shape[0]), epoch_data_mean - epoch_data_sem, epoch_data_mean + epoch_data_sem, color=colors[channel_type], alpha=0.3)\n",
    "            \n",
    "            ax.set_xlabel('Time (s)', fontsize=20)\n",
    "            ax.set_ylabel('uM', fontsize=20)\n",
    "            ax.set_title(f'Averaged Epochs for {mode}: {condition}', fontsize=24)\n",
    "            ax.legend(fontsize=20)\n",
    "            ax.set_ylim(-3e-6, 3e-6) # set the ylims to -+3 * 10^-6\n",
    "            \n",
    "            # set the xticks to the time points, 0-18 seconds, instead of 103 time points\n",
    "            ax.set_xticks(np.arange(0, 103, 6))\n",
    "            ax.set_xticklabels(np.arange(0, 103, 6) // 6)  # Ensure the number of labels matches the number of ticks\n",
    "            # set the fontsize of the xticks to 20\n",
    "            ax.tick_params(axis='x', labelsize=20)\n",
    "            # set the fontsize of the yticks to 20\n",
    "            ax.tick_params(axis='y', labelsize=20)\n",
    "            plt.tight_layout(pad=0)\n",
    "            plt.savefig(f'plots/erp/erp_conditions/{condition}.png', dpi=dpi / 2)\n",
    "            plt.close()\n",
    "\n",
    "        for cond1, cond2 in itertools.combinations(conditions_list[mode], 2):\n",
    "            # create a 8x1 subplot that shares the x-axis and i can iterate over\n",
    "            fig, axes = plt.subplots(8, 1, figsize=(12, 24), sharex=True)        \n",
    "\n",
    "            # in ch_mapping_all, for each list of channels in the dict, filter for the channels with difference_channel_type in the string\n",
    "            groups = {region: [channel for channel in channels if difference_channel_type in channel] for region, channels in mappings['ch_mapping_all'].items()}\n",
    "            group_i = 0\n",
    "            for region, ch_name in groups.items():\n",
    "                # Get the indices for the current region from group_boundaries\n",
    "                keys_list = list(groups.keys())\n",
    "                start_idx = mappings['group_boundaries'][keys_list.index(region)]\n",
    "                end_idx = mappings['group_boundaries'][keys_list.index(region) + 1] if keys_list.index(region) + 1 < len(mappings['group_boundaries']) else None\n",
    "\n",
    "                # get the data for the current region\n",
    "                epoch_data_region1 = np.nanmean(epochs[mode][cond1][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
    "                epoch_data_region2 = np.nanmean(epochs[mode][cond2][:, :, dict_channel_types[difference_channel_type], start_idx:end_idx], axis=(1, 2))\n",
    "\n",
    "                # get the mean of the data\n",
    "                epoch_data_region1_mean = np.nanmean(epoch_data_region1, axis=0)\n",
    "                epoch_data_region2_mean = np.nanmean(epoch_data_region2, axis=0)\n",
    "\n",
    "                # get the standard error of the mean\n",
    "                epoch_data_region1_sem = np.nanstd(epoch_data_region1, axis=0) / np.sqrt(epoch_data_region1.shape[0])\n",
    "                epoch_data_region2_sem = np.nanstd(epoch_data_region2, axis=0) / np.sqrt(epoch_data_region2.shape[0])\n",
    "\n",
    "                # plot the mean\n",
    "                axes[group_i].plot(epoch_data_region1_mean, label=cond1, color='red')\n",
    "                axes[group_i].plot(epoch_data_region2_mean, label=cond2, color='blue')\n",
    "\n",
    "                # plot the standard error of the mean as a shaded area\n",
    "                axes[group_i].fill_between(np.arange(epoch_data_region1_mean.shape[0]), epoch_data_region1_mean - epoch_data_region1_sem, epoch_data_region1_mean + epoch_data_region1_sem, color='red', alpha=0.3)\n",
    "                axes[group_i].fill_between(np.arange(epoch_data_region2_mean.shape[0]), epoch_data_region2_mean - epoch_data_region2_sem, epoch_data_region2_mean + epoch_data_region2_sem, color='blue', alpha=0.3)\n",
    "\n",
    "                # set the title of the subplot to the region\n",
    "                if group_i == 0:\n",
    "                    axes[group_i].set_title(f'Averaged Epochs by ROI for {mode}: {cond1} - {cond2}, {difference_channel_type}\\n{region}', fontsize=24)\n",
    "                else:\n",
    "                    axes[group_i].set_title(region, fontsize=24)\n",
    "                \n",
    "                # set the ylims to -+7 * 10^-6\n",
    "                axes[group_i].set_ylim(-7e-6, 7e-6)\n",
    "\n",
    "                # add a legend to the subplot\n",
    "                axes[group_i].legend(fontsize=20)\n",
    "\n",
    "                group_i += 1\n",
    "\n",
    "            axes[-1].set_xlabel('Time (s)', fontsize=20)\n",
    "            # set the xticks to the time points, 0-18 seconds, instead of 103 time points\n",
    "            axes[-1].set_xticks(np.arange(0, 103, 6))\n",
    "            axes[-1].set_xticklabels(np.arange(0, 103, 6) // 6)  # Ensure the number of labels matches the number of ticks\n",
    "            # set the fontsize of the xticks to 20\n",
    "            axes[-1].tick_params(axis='x', labelsize=20)\n",
    "            # set the fontsize of the yticks to 20\n",
    "            axes[-1].tick_params(axis='y', labelsize=20)\n",
    "            axes[-1].set_ylabel('uM', fontsize=20)\n",
    "            plt.tight_layout(pad=0)\n",
    "            if \"Neutral\" == cond1 or \"Neutral\" == cond2:\n",
    "                plt.savefig(f'plots/erp/erp_differences_neutral/{cond1}_{cond2}.png', dpi=dpi / 2)\n",
    "            else:\n",
    "                plt.savefig(f'plots/erp/erp_differences/{cond1}_{cond2}.png', dpi=dpi / 2)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = ['all', 'face_type', 'emotion', 'face_type_emotion']\n",
    "conditions_list = {\n",
    "    'all': ['Blck', 'Base'],\n",
    "    'face_type': ['Real', 'Virt'],\n",
    "    'emotion': ['Joy', 'Fear', 'Anger', 'Disgust', 'Sadness', 'Neutral', 'Surprise'],\n",
    "    'face_type_emotion': ['Real_Joy', 'Real_Fear', 'Real_Anger', 'Real_Disgust', 'Real_Sadness', 'Real_Neutral', 'Real_Surprise',\n",
    "                          'Virt_Joy', 'Virt_Fear', 'Virt_Anger', 'Virt_Disgust', 'Virt_Sadness', 'Virt_Neutral', 'Virt_Surprise']\n",
    "}\n",
    "\n",
    "connectivity_method = [spectral_connectivity_time]\n",
    "\n",
    "# pick the channels\n",
    "channel_types = ['hbo', 'hbr', 'hbt']\n",
    "\n",
    "# make a dictionary to store the channel types and their indices\n",
    "dict_channel_types = {\n",
    "    channel_type: idx for idx, channel_type in enumerate(channel_types)\n",
    "}\n",
    "\n",
    "# main channel type\n",
    "channel_type = 'hbt'\n",
    "\n",
    "# sampling frequency\n",
    "sfreq = 6.105006105006105\n",
    "\n",
    "# pick the connectivity method\n",
    "method = \"coh\"\n",
    "\n",
    "# pick the mode\n",
    "con_mode = \"cwt_morlet\"\n",
    "\n",
    "# pick the frequency range\n",
    "cwt_freqs = np.linspace(0.2, 0.5, 5)\n",
    "\n",
    "# pick the number of cycles\n",
    "cwt_n_cycles = 1\n",
    "\n",
    "# average the connectivity matrices across frequencies\n",
    "faverage = True\n",
    "\n",
    "if run_ind_connectivity:\n",
    "    # We now have epochs[mode][condition].shape = (n_participants, n_epochs, n_channel_types, n_channels, n_times)\n",
    "    epochs = {\n",
    "        mode: {\n",
    "            condition: np.load(f'processed_data/epochs/{mode}_{condition}_epochs.npy')\n",
    "            for condition in conditions_list[mode]\n",
    "        }\n",
    "        for mode in modes\n",
    "    }\n",
    "\n",
    "    # for each connectivity method, mode and condition, calculate the connectivity for each participant\n",
    "    for func in connectivity_method:\n",
    "        for mode in modes:\n",
    "            for condition in conditions_list[mode]:\n",
    "                # create an empty list to store the connectivity for each participant\n",
    "                participant_cons = []\n",
    "\n",
    "                for participant in range(epochs[mode][condition].shape[0]):\n",
    "\n",
    "                    # create an empty list to store the connectivity for each channel type\n",
    "                    channel_cons = []\n",
    "                    \n",
    "                    for channel_type in channel_types:\n",
    "                        # get the data for the current participant and channel type\n",
    "                        epoch_data = epochs[mode][condition][participant, :, dict_channel_types[channel_type], :]\n",
    "\n",
    "                        # get the maximum number of time points across all epochs without NaN values\n",
    "                        n_times_max = int(np.nanmax(np.sum(~np.isnan(epoch_data[:, 0, :]), axis=1)))\n",
    "\n",
    "                        # reshape the data to (n_epochs, n_channels, n_times_max)\n",
    "                        epoch_data = epoch_data[:, :, :n_times_max]\n",
    "\n",
    "                        if func.__name__ == 'spectral_connectivity_time':\n",
    "                            con = func(\n",
    "                                epoch_data,\n",
    "                                method=method,\n",
    "                                mode=con_mode,\n",
    "                                freqs=cwt_freqs,\n",
    "                                n_cycles=cwt_n_cycles,\n",
    "                                faverage=faverage,\n",
    "                                sfreq=sfreq,\n",
    "                                n_jobs=n_jobs,\n",
    "                                verbose=False\n",
    "                            )\n",
    "                        else:\n",
    "                            raise ValueError(f\"Unknown connectivity method: {func.__name__}\")\n",
    "\n",
    "                        data = con.get_data()\n",
    "\n",
    "                        channel_cons.append(data)\n",
    "\n",
    "                    participant_cons.append(np.array(channel_cons))\n",
    "\n",
    "                # save the connectivity to a file\n",
    "                np.save(f'processed_data\\\\{func.__name__}\\\\individual_cons\\\\{mode}_{condition}_con.npy', np.array(participant_cons))\n",
    "\n",
    "        # make a dictionary to store the connectivity parameters\n",
    "        ind_connectivity_params = {\n",
    "            \"func\": func.__name__,\n",
    "            \"channel_types\": channel_types,\n",
    "            \"method\": method,\n",
    "            \"con_mode\": con_mode,\n",
    "            \"cwt_freqs\": cwt_freqs.tolist(),\n",
    "            \"cwt_n_cycles\": cwt_n_cycles,\n",
    "            \"faverage\": faverage\n",
    "        }\n",
    "\n",
    "        # save the connectivity parameters to disk in preprocessed_data\\connectivity\n",
    "        with open(f\"processed_data\\\\{func.__name__}\\\\ind_connectivity_params.json\", \"w\") as f:\n",
    "            json.dump(ind_connectivity_params, f)\n",
    "\n",
    "# load the numpy files from disk so we have ind_con[func_name][mode][condition].shape = (n_participants, n_channel_types, n_epochs, n_channels, n_freqs)\n",
    "ind_con = {\n",
    "    func.__name__: {\n",
    "        mode: {\n",
    "            condition: np.load(f'processed_data\\\\{func.__name__}\\\\individual_cons\\\\{mode}_{condition}_con.npy')\n",
    "            for condition in conditions_list[mode]\n",
    "        }\n",
    "        for mode in modes\n",
    "    }\n",
    "    for func in connectivity_method\n",
    "}\n",
    "\n",
    "ind_connectivity_params = {\n",
    "    func.__name__: json.load(open(f\"processed_data\\\\{func.__name__}\\\\ind_connectivity_params.json\", \"r\"))\n",
    "    for func in connectivity_method\n",
    "}\n",
    "\n",
    "dict_channel_types = {\n",
    "    channel_type: idx for idx, channel_type in enumerate(channel_types)\n",
    "}\n",
    "\n",
    "participants = ind_con[connectivity_method[0].__name__][modes[0]][conditions_list[modes[0]][0]].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition Connectivity Heatmap/Chord Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_condition_con_plots:\n",
    "\n",
    "    # make a color scheme\n",
    "    colorscheme = dict(\n",
    "        facecolor='white',\n",
    "        textcolor='black',\n",
    "        colormap='hot',\n",
    "        facecolor2='black',\n",
    "        textcolor2='white',\n",
    "        node_colors=['lightgrey'] * len(mappings['ch_names_original'])\n",
    "    )\n",
    "\n",
    "    # get the node angles\n",
    "    node_angles = circular_layout(\n",
    "        mappings['ch_names_original'], mappings['all_channels_names'], start_pos=90, group_boundaries=mappings['group_boundaries']\n",
    "    )\n",
    "\n",
    "    for func in connectivity_method:\n",
    "        for mode in modes:\n",
    "            for condition in conditions_list[mode]:\n",
    "                averaged_data = np.nanmean(ind_con[func.__name__][mode][condition][:, dict_channel_types[channel_type]], axis=(0, 1, 3))\n",
    "                \n",
    "                # Get the grid size\n",
    "                grid_size = int(np.sqrt(averaged_data.size))\n",
    "\n",
    "                # Reshape the data into a 2D grid\n",
    "                heatmap_data = averaged_data.reshape((grid_size, grid_size))\n",
    "\n",
    "                # Make the matrix symmetric\n",
    "                symmetric_data = heatmap_data + heatmap_data.T\n",
    "\n",
    "                # Set the diagonal to the highest value\n",
    "                np.fill_diagonal(symmetric_data, np.max(symmetric_data))\n",
    "\n",
    "                # Plot the heatmap\n",
    "                fig, ax = plt.subplots(figsize=(25, 25))\n",
    "                im = ax.imshow(symmetric_data, cmap='viridis')\n",
    "                ax.set_title(f'Connectivity Heatmap for {func.__name__}, Mode: {mode}, Condition: {condition}, Channel Type: {channel_type}')\n",
    "                ax.set_xlabel('Channel')\n",
    "                ax.set_ylabel('Channel')\n",
    "                ax.set_xticks(np.arange(grid_size))\n",
    "                ax.set_yticks(np.arange(grid_size))\n",
    "                ax.set_xticklabels(mappings['all_channels_names'])\n",
    "                ax.set_yticklabels(mappings['all_channels_names'])\n",
    "                plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "                cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "                cbar.set_label('Connectivity Value')\n",
    "                plt.savefig(f'plots/{func.__name__}/heatmaps/conditions/{mode}_{condition}_con.png', dpi=dpi / 4)\n",
    "                plt.close()\n",
    "\n",
    "                # find the min of the averaged_data, when dropping all the 0s\n",
    "                min_val = np.min(averaged_data[np.nonzero(averaged_data)])\n",
    "\n",
    "                # find the max of the averaged_data, when dropping all the 0s\n",
    "                max_val = np.max(averaged_data[np.nonzero(averaged_data)])\n",
    "\n",
    "                # Plot the connectivity circle\n",
    "                plot_connectivity_circle(\n",
    "                    heatmap_data,\n",
    "                    node_names=mappings['ch_names_original'],\n",
    "                    node_angles=node_angles,\n",
    "                    n_lines=10000,\n",
    "                    colorbar_size=1,\n",
    "                    fontsize_colorbar=16,\n",
    "                    facecolor=colorscheme['facecolor'],\n",
    "                    textcolor=colorscheme['textcolor'],\n",
    "                    colormap=colorscheme['colormap'],\n",
    "                    node_colors=colorscheme['node_colors'],\n",
    "                    padding=3,\n",
    "                    vmin=min_val,\n",
    "                    vmax=max_val,\n",
    "                    colorbar=True,\n",
    "                    show=False\n",
    "                )\n",
    "                plt.title(f'Connectivity: {condition}, {channel_type}', fontsize=24)\n",
    "                plt.savefig(f'plots/{func.__name__}/chord_plots/conditions/{mode}_{condition}_con.png', dpi=dpi / 4)\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition Connectivity Variance Across Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_variance_con_plots:\n",
    "    for mode in modes:\n",
    "        vmax = None\n",
    "        for condition in conditions_list[mode]:\n",
    "            # the shape of averaged_data is (n_participants, n_channels)\n",
    "            averaged_data = np.nanmean(ind_con['spectral_connectivity_time'][mode][condition][:, dict_channel_types[channel_type], :, :, 0], axis=1)\n",
    "\n",
    "            # reshape the data to (n_participants, n_channels, n_channels)\n",
    "            averaged_data = averaged_data.reshape(averaged_data.shape[0], int(np.sqrt(averaged_data.shape[1])), int(np.sqrt(averaged_data.shape[1])))\n",
    "\n",
    "            # make the matrix symmetric for the (sqrt(n_channels), sqrt(n_channels)) part\n",
    "            for matrix in averaged_data:\n",
    "                matrix += matrix.T\n",
    "                np.fill_diagonal(matrix, np.nanmax(matrix))\n",
    "\n",
    "            # create a matrix of the variance of each channel pair over all participants\n",
    "            variance_matrix = np.nanvar(averaged_data, axis=0)\n",
    "\n",
    "            # Plot the heatmap\n",
    "            fig, ax = plt.subplots(figsize=(10, 10))\n",
    "            im = ax.imshow(variance_matrix, cmap='viridis')\n",
    "            ax.set_title(f'Variance Heatmap for Mode: {mode}, Condition: {condition}, Channel Type: {channel_type}')\n",
    "            ax.set_xlabel('Channel')\n",
    "            ax.set_ylabel('Channel')\n",
    "            \n",
    "            cbar = plt.colorbar(im, ax=ax)\n",
    "            cbar.set_label('Variance Value')\n",
    "            if vmax is None:\n",
    "                vmax = variance_matrix.max()\n",
    "            \n",
    "            im.set_clim(0, vmax)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            plt.savefig(f'plots/spectral_connectivity_time/heatmaps/variance/{mode}_{condition}_variance.png', dpi=dpi / 4)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Level Connectivity t-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_group_level_t_tests:\n",
    "    for func in connectivity_method:\n",
    "        for mode in modes:\n",
    "            for condition1, condition2 in itertools.combinations(conditions_list[mode], 2):\n",
    "                # Get the data for the two conditions\n",
    "                data1 = np.nanmean(ind_con[func.__name__][mode][condition1][:, dict_channel_types[channel_type]], axis=(1, 3))\n",
    "                data2 = np.nanmean(ind_con[func.__name__][mode][condition2][:, dict_channel_types[channel_type]], axis=(1, 3))\n",
    "\n",
    "                # reshape the data to (num_participants, int(np.sqrt(num_channel_connections)), int(np.sqrt(num_channel_connections)))\n",
    "                data1 = data1.reshape(data1.shape[0], int(np.sqrt(data1.shape[1])), int(np.sqrt(data1.shape[1])))\n",
    "                data2 = data2.reshape(data2.shape[0], int(np.sqrt(data2.shape[1])), int(np.sqrt(data2.shape[1])))\n",
    "\n",
    "                # ensure the data shapes are the same\n",
    "                assert data1.shape == data2.shape\n",
    "\n",
    "                # ensure the data is not empty or contains NaNs\n",
    "                assert not np.isnan(data1).any()\n",
    "                assert not np.isnan(data2).any()\n",
    "\n",
    "                # apply fisher z transform to the data\n",
    "                data1 = np.arctanh(data1)\n",
    "                data2 = np.arctanh(data2)\n",
    "\n",
    "                # Initialize matrices to store t and p-values\n",
    "                t_vals = np.zeros(data1.shape[1:])\n",
    "                p_values = np.zeros(data1.shape[1:])\n",
    "\n",
    "                # Iterate over each pair of channels\n",
    "                for i in range(data1.shape[1]):\n",
    "                    for j in range(i): # because the matrix is lower triangular\n",
    "                        # Run the t-test\n",
    "                        t_val, p_val = stats.ttest_rel(data1[:, i, j], data2[:, i, j])\n",
    "\n",
    "                        # Store the results\n",
    "                        t_vals[i, j] = t_val\n",
    "                        p_values[i, j] = p_val\n",
    "\n",
    "                # Flatten the lower triangular valid p-values (non-nan) for FDR correction\n",
    "                valid_idx = ~np.isnan(p_values)\n",
    "                p_values_flat = p_values[valid_idx]\n",
    "\n",
    "                # Correct p-values for multiple comparisons\n",
    "                _, p_values_flat_fdr = fdrcorrection(p_values_flat)\n",
    "\n",
    "                # Reshape the corrected p-values back to matrix form\n",
    "                p_values_fdr = p_values_flat_fdr.reshape(p_values.shape)\n",
    "\n",
    "                # Save the p-values to disk\n",
    "                np.save(f'processed_data\\\\{func.__name__}\\\\paired_t_tests_p_vals\\\\{mode}_{condition1}_{condition2}_p_values.npy', p_values_fdr)\n",
    "\n",
    "                # Save the t-values to disk\n",
    "                np.save(f'processed_data\\\\{func.__name__}\\\\paired_t_tests_t_vals\\\\{mode}_{condition1}_{condition2}_t_values.npy', t_vals)\n",
    "\n",
    "# Load the t-values and p-values from disk and combine them into one dictionary\n",
    "group_level_t_tests = {\n",
    "    func.__name__: {\n",
    "        mode: {\n",
    "            f\"{condition1}_{condition2}\": {\n",
    "                \"p_vals\": np.load(f'processed_data\\\\{func.__name__}\\\\paired_t_tests_p_vals\\\\{mode}_{condition1}_{condition2}_p_values.npy'),\n",
    "                \"t_vals\": np.load(f'processed_data\\\\{func.__name__}\\\\paired_t_tests_t_vals\\\\{mode}_{condition1}_{condition2}_t_values.npy')\n",
    "            }\n",
    "            for condition1, condition2 in itertools.combinations(conditions_list[mode], 2)\n",
    "        }\n",
    "        for mode in modes\n",
    "    }\n",
    "    for func in connectivity_method\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Level Connectivity t-test Chord Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_group_level_t_tests_chord_plots:\n",
    "\n",
    "    # make a color scheme\n",
    "    colorscheme = dict(\n",
    "        facecolor='white',\n",
    "        textcolor='black',\n",
    "        colormap='berlin',\n",
    "        facecolor2='black',\n",
    "        textcolor2='white',\n",
    "        node_colors=['lightgrey'] * len(mappings['ch_names_original'])\n",
    "    )\n",
    "\n",
    "    # get the node angles\n",
    "    node_angles = circular_layout(\n",
    "        mappings['ch_names_original'], mappings['all_channels_names'], start_pos=90, group_boundaries=mappings['group_boundaries']\n",
    "    )\n",
    "    \n",
    "    for func in connectivity_method:\n",
    "        for mode in modes:\n",
    "            for condition1, condition2 in itertools.combinations(conditions_list[mode], 2):\n",
    "                t_values = group_level_t_tests[func.__name__][mode][f\"{condition1}_{condition2}\"]['t_vals']\n",
    "\n",
    "                p_values = group_level_t_tests[func.__name__][mode][f\"{condition1}_{condition2}\"]['p_vals']\n",
    "\n",
    "                # Set the t-values to 0 where the p-values are not significant\n",
    "                t_values[p_values > 0.05] = 0\n",
    "\n",
    "                # Set the diagonal to 0\n",
    "                np.fill_diagonal(t_values, 0)\n",
    "\n",
    "                plot_connectivity_circle(\n",
    "                    t_values,\n",
    "                    node_names=mappings['ch_names_original'],\n",
    "                    node_angles=node_angles,\n",
    "                    n_lines=10000,\n",
    "                    colorbar_size=1,\n",
    "                    fontsize_colorbar=16,\n",
    "                    facecolor=colorscheme['facecolor'],\n",
    "                    textcolor=colorscheme['textcolor'],\n",
    "                    colormap=colorscheme['colormap'],\n",
    "                    node_colors=colorscheme['node_colors'],\n",
    "                    padding=3,\n",
    "                    vmin=-4,\n",
    "                    vmax=4,\n",
    "                    colorbar=True,\n",
    "                    show=False\n",
    "                )\n",
    "                plt.title(f'Significantly different Channels: {condition1} > {condition2}, {channel_type}', fontsize=20)\n",
    "                plt.savefig(f'plots/{func.__name__}/chord_plots/group_level_t_tests/{mode}_{condition1}_{condition2}.png', dpi=dpi / 4)\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Level Connectivity t-test ROI Chord Plots\n",
    "Remember to edit the plot_connectivity_circle function to include the diagonals: \\mne\\viz\\circle.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\super\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "if get_group_level_t_tests_roi_chord_plots:\n",
    "    # make an empty dataframe to store the matrix data\n",
    "    roi_p_vals = pd.DataFrame()\n",
    "    roi_t_vals = pd.DataFrame()\n",
    "\n",
    "    # Get the names of the regions\n",
    "    regions = list(mappings['ch_mapping_names'].keys())\n",
    "\n",
    "    colorscheme = dict(\n",
    "        facecolor='white',\n",
    "        textcolor='black',\n",
    "        colormap='bwr',\n",
    "        facecolor2='black',\n",
    "        textcolor2='white',\n",
    "    )\n",
    "\n",
    "    # get the node angles\n",
    "    node_angles = circular_layout(\n",
    "        regions, regions, start_pos=90\n",
    "    )\n",
    "\n",
    "    # First, flatten the dictionary into a list of tuples (channel_name, region)\n",
    "    flat_list = [(channel, region) for region, channels in mappings['ch_mapping_names'].items() for channel in channels]\n",
    "\n",
    "    # Now, replace the channel name with its enumeration (starting from 0)\n",
    "    reshaped_list = [(i, region) for i, (_, region) in enumerate(flat_list)]\n",
    "\n",
    "    for func in connectivity_method:\n",
    "        for mode in modes:\n",
    "            for condition1, condition2 in itertools.combinations(conditions_list[mode], 2):\n",
    "                t_values_by_roi = {}\n",
    "                p_values_by_roi = {}\n",
    "\n",
    "                for i, row in enumerate(group_level_t_tests[func.__name__][mode][f'{condition1}_{condition2}']['t_vals']):\n",
    "                    region_i = reshaped_list[i][1]\n",
    "                    for j, element in enumerate(row):\n",
    "                        region_j = reshaped_list[j][1]\n",
    "\n",
    "                        # skip the zeros\n",
    "                        if element == 0:\n",
    "                            continue\n",
    "\n",
    "                        # Store the significant t-values and p-values for each ROI pair\n",
    "                        if f'{region_i}_{region_j}' not in t_values_by_roi:\n",
    "                            t_values_by_roi[f'{region_i}_{region_j}'] = [element]\n",
    "                            p_values_by_roi[f'{region_i}_{region_j}'] = [group_level_t_tests[func.__name__][mode][f'{condition1}_{condition2}']['p_vals'][i][j]]\n",
    "                        else:\n",
    "                            t_values_by_roi[f'{region_i}_{region_j}'].append(element)\n",
    "                            p_values_by_roi[f'{region_i}_{region_j}'].append(group_level_t_tests[func.__name__][mode][f'{condition1}_{condition2}']['p_vals'][i][j])\n",
    "\n",
    "                for roi_pair, p_values in p_values_by_roi.items():\n",
    "                    # set the t-values to 0 where the p-values are not significant\n",
    "                    t_values_by_roi[roi_pair] = [t_value for t_value, p_value in zip(t_values_by_roi[roi_pair], p_values) if p_value < 0.05]\n",
    "\n",
    "                    # Get the mean t-value for the ROI pair\n",
    "                    t_values_by_roi[roi_pair] = np.mean(t_values_by_roi[roi_pair])\n",
    "\n",
    "                    # filter out the p_values that are greater than 0.05\n",
    "                    p_values_by_roi[roi_pair] = [p_value for p_value in p_values if p_value < 0.05]\n",
    "\n",
    "                    # Get the count of p-values for each ROI pair\n",
    "                    p_values_by_roi[roi_pair] = len(p_values_by_roi[roi_pair])\n",
    "\n",
    "                # Create a matrix filled with NaNs\n",
    "                t_matrix = np.full((len(regions), len(regions)), np.nan)\n",
    "\n",
    "                # Create a matrix filled with NaNs for p-values\n",
    "                p_matrix = np.full((len(regions), len(regions)), np.nan)\n",
    "\n",
    "                # Fill the matrix using the dictionary values\n",
    "                for key, value in t_values_by_roi.items():\n",
    "                    r1, r2 = key.split('_')\n",
    "                    i = regions.index(r1)\n",
    "                    j = regions.index(r2)\n",
    "                    # Fill the lower triangular part of the matrix\n",
    "                    if i > j:\n",
    "                        t_matrix[i, j] = value\n",
    "                    else:\n",
    "                        t_matrix[j, i] = value\n",
    "\n",
    "                # Fill the p-values matrix using the dictionary values\n",
    "                for key, value in p_values_by_roi.items():\n",
    "                    r1, r2 = key.split('_')\n",
    "                    i = regions.index(r1)\n",
    "                    j = regions.index(r2)\n",
    "                    # Fill the lower triangular part of the matrix\n",
    "                    if i > j:\n",
    "                        p_matrix[i, j] = value\n",
    "                    else:\n",
    "                        p_matrix[j, i] = value\n",
    "\n",
    "                # Create dictionaries to hold the t-values and p-values data\n",
    "                t_data_dict = {}\n",
    "                p_data_dict = {}\n",
    "                for i in range(len(regions)):\n",
    "                    for j in range(len(regions)):\n",
    "                        if not np.isnan(t_matrix[i, j]):\n",
    "                            key = f\"{regions[i]}_{regions[j]}\"\n",
    "                            t_data_dict[key] = t_matrix[i, j]\n",
    "                        if not np.isnan(p_matrix[i, j]):\n",
    "                            key = f\"{regions[i]}_{regions[j]}\"\n",
    "                            p_data_dict[key] = p_matrix[i, j]\n",
    "\n",
    "                # Create DataFrames from the dictionaries\n",
    "                t_df = pd.DataFrame([t_data_dict])\n",
    "                p_df = pd.DataFrame([p_data_dict])\n",
    "\n",
    "                # Add the condition and mode as the first two columns in the DataFrames\n",
    "                t_df.insert(0, 'Mode', mode)\n",
    "                t_df.insert(1, 'Condition', f\"{condition1}_{condition2}\")\n",
    "                p_df.insert(0, 'Mode', mode)\n",
    "                p_df.insert(1, 'Condition', f\"{condition1}_{condition2}\")\n",
    "\n",
    "                # Append the DataFrames to the matrix_data DataFrame\n",
    "                roi_t_vals = pd.concat([roi_t_vals, t_df], ignore_index=True)\n",
    "                roi_p_vals = pd.concat([roi_p_vals, p_df], ignore_index=True)\n",
    "\n",
    "                # Plot the connectivity circle\n",
    "                plot_connectivity_circle(\n",
    "                    t_matrix,\n",
    "                    node_names=regions,\n",
    "                    node_angles=node_angles,\n",
    "                    n_lines=10000,\n",
    "                    colorbar_size=1,\n",
    "                    fontsize_colorbar=16,\n",
    "                    node_width=40,\n",
    "                    linewidth=4.5,\n",
    "                    facecolor=colorscheme['facecolor'],\n",
    "                    textcolor=colorscheme['textcolor'],\n",
    "                    colormap=colorscheme['colormap'],\n",
    "                    padding=3,\n",
    "                    vmin=-4,\n",
    "                    vmax=4,\n",
    "                    fontsize_names=12,\n",
    "                    colorbar=True,\n",
    "                    show=False\n",
    "                )\n",
    "                plt.suptitle(f'Mean t-value by ROI: {condition1} > {condition2}\\nMean t-value across ROI\\'s: {np.round(np.nanmean(t_matrix), 2)}', fontsize=22)\n",
    "                plt.savefig(f'plots/spectral_connectivity_time/chord_plots/group_level_t_tests_roi/{mode}_{condition1}_{condition2}.png', dpi=dpi / 2)\n",
    "                plt.close()\n",
    "\n",
    "    # Save the t-values and p-values DataFrames to CSV files\n",
    "    roi_t_vals.to_csv(f'processed_data\\\\spectral_connectivity_time\\\\group_level_t_tests_roi_t_vals.csv', index=False)\n",
    "    roi_p_vals.to_csv(f'processed_data\\\\spectral_connectivity_time\\\\group_level_t_tests_roi_p_vals.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Level Connectivity t-test ROI Emotion Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_emotion_analysis_plots:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    roi_t_vals = pd.read_csv(f'processed_data\\\\spectral_connectivity_time\\\\group_level_t_tests_roi_t_vals.csv')\n",
    "    roi_t_vals = roi_t_vals[roi_t_vals['Mode'] == 'emotion']\n",
    "\n",
    "    # Split Condition into two columns and reorder them\n",
    "    roi_t_vals = roi_t_vals.assign(\n",
    "        Condition1=roi_t_vals['Condition'].str.split('_').str[0],\n",
    "        Condition2=roi_t_vals['Condition'].str.split('_').str[1]\n",
    "    ).drop(columns=['Condition'])\n",
    "\n",
    "    # Reorder columns to place Condition1 and Condition2 after Mode\n",
    "    cols = ['Mode', 'Condition1', 'Condition2'] + [col for col in roi_t_vals.columns if col not in ['Mode', 'Condition1', 'Condition2']]\n",
    "    roi_t_vals = roi_t_vals[cols]\n",
    "\n",
    "    # Get the unique conditions from Condition1 and Condition2\n",
    "    unique_conditions = pd.Series(roi_t_vals['Condition1'].tolist() + roi_t_vals['Condition2'].tolist()).unique()\n",
    "\n",
    "    # Prepare a matrix for the heatmap: rows and columns are unique_conditions, values are mean across all ROIs for each pair\n",
    "    heatmap_matrix = np.full((len(unique_conditions), len(unique_conditions)), np.nan)\n",
    "    for i, cond1 in enumerate(unique_conditions):\n",
    "        for j, cond2 in enumerate(unique_conditions):\n",
    "            if i >= j:  # Only fill lower triangle (including diagonal)\n",
    "                mask = (\n",
    "                    ((roi_t_vals['Condition1'] == cond1) & (roi_t_vals['Condition2'] == cond2)) |\n",
    "                    ((roi_t_vals['Condition1'] == cond2) & (roi_t_vals['Condition2'] == cond1))\n",
    "                )\n",
    "                if mask.any():\n",
    "                    # Drop Mode, Condition1, Condition2 columns, then mean across all ROI columns for this pair\n",
    "                    vals = roi_t_vals.loc[mask].drop(columns=['Mode', 'Condition1', 'Condition2']).mean(axis=1)\n",
    "                    heatmap_matrix[i, j] = vals.mean()\n",
    "\n",
    "    # Set the diagonal to 0\n",
    "    np.fill_diagonal(heatmap_matrix, 0)\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    im = plt.imshow(heatmap_matrix, cmap='bwr', aspect='auto', vmin=-3, vmax=3)\n",
    "    cbar = plt.colorbar(im, label='Mean t-value')\n",
    "    cbar.ax.tick_params(labelsize=20)  # Increase colorbar tick size\n",
    "    cbar.set_label('Mean t-value', fontsize=24)  # Increase colorbar label size\n",
    "    plt.xticks(ticks=np.arange(len(unique_conditions)), labels=unique_conditions, rotation=45, fontsize=20)\n",
    "    plt.yticks(ticks=np.arange(len(unique_conditions)), labels=unique_conditions, fontsize=20)\n",
    "    plt.xlabel('Emotion 1', fontsize=24)\n",
    "    plt.ylabel('Emotion 2', fontsize=24)\n",
    "    plt.title('Mean t-value by Emotion Pair across ROI\\'s\\nContrast: Emotion 1 > Emotion 2', fontsize=28)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig(f'plots/spectral_connectivity_time/emotion_analysis/Mean_t-value_by_Emotion_Pair.png', dpi=dpi / 2)\n",
    "    plt.close()\n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    roi_p_vals = pd.read_csv(f'processed_data\\\\spectral_connectivity_time\\\\group_level_t_tests_roi_p_vals.csv')\n",
    "    roi_p_vals = roi_p_vals[roi_p_vals['Mode'] == 'emotion']\n",
    "\n",
    "    # Split Condition into two columns and reorder them\n",
    "    roi_p_vals = roi_p_vals.assign(\n",
    "        Condition1=roi_p_vals['Condition'].str.split('_').str[0],\n",
    "        Condition2=roi_p_vals['Condition'].str.split('_').str[1]\n",
    "    ).drop(columns=['Condition'])\n",
    "\n",
    "    # Reorder columns to place Condition1 and Condition2 after Mode\n",
    "    cols = ['Mode', 'Condition1', 'Condition2'] + [col for col in roi_p_vals.columns if col not in ['Mode', 'Condition1', 'Condition2']]\n",
    "    roi_p_vals = roi_p_vals[cols]\n",
    "\n",
    "    # Get the unique conditions from Condition1 and Condition2\n",
    "    unique_conditions = pd.Series(roi_p_vals['Condition1'].tolist() + roi_p_vals['Condition2'].tolist()).unique()\n",
    "\n",
    "    all_conditions = pd.DataFrame()\n",
    "    for condition in unique_conditions:\n",
    "        # Filter the DataFrame for the current condition in both Condition1 and Condition2\n",
    "        condition_data = roi_p_vals[(roi_p_vals['Condition1'] == condition) | (roi_p_vals['Condition2'] == condition)]\n",
    "\n",
    "        # drop the Mode column\n",
    "        condition_data = condition_data.drop(columns=['Mode'])\n",
    "\n",
    "        # Create a new column 'Condition' based on the current condition\n",
    "        condition_data.insert(0, 'Condition', condition)\n",
    "\n",
    "        # drop the Condition1 and Condition2 columns\n",
    "        condition_data = condition_data.drop(columns=['Condition1', 'Condition2'])\n",
    "\n",
    "        # average the data for the current condition\n",
    "        condition_data = condition_data.groupby('Condition').mean().reset_index()\n",
    "\n",
    "        # Concatenate the filtered DataFrame to all_conditions\n",
    "        all_conditions = pd.concat([all_conditions, condition_data], ignore_index=True)\n",
    "\n",
    "    # compute the mean across all columns except 'Condition'\n",
    "    all_conditions['RegionSum'] = all_conditions.drop(columns='Condition').sum(axis=1)\n",
    "\n",
    "    # keep only Condition + the new mean column\n",
    "    all_conditions = all_conditions[['Condition', 'RegionSum']]\n",
    "\n",
    "    # sort the dataframe by RegionMean\n",
    "    all_conditions = all_conditions.sort_values(by='RegionSum', ascending=True)\n",
    "\n",
    "    # reset the index\n",
    "    all_conditions = all_conditions.reset_index(drop=True)\n",
    "\n",
    "    # produce a bar plot of the mean values for each condition\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    plt.barh(all_conditions['Condition'], all_conditions['RegionSum'], color=plt.cm.Wistia(np.linspace(0, 1, len(all_conditions))))\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.xlabel('Count of significantly different channel pairs', fontsize=24)\n",
    "    plt.ylabel('Emotion', fontsize=20)\n",
    "    plt.title('Count of significantly different channel pairs summed across all Regions,\\nby Emotion', fontsize=24)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/spectral_connectivity_time/emotion_analysis/Count_of_Significant_Channel_Pairs_by_Emotion.png', dpi=dpi / 2)\n",
    "    plt.close()\n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    roi_p_vals = pd.read_csv(f'processed_data\\\\spectral_connectivity_time\\\\group_level_t_tests_roi_p_vals.csv')\n",
    "    roi_p_vals = roi_p_vals[roi_p_vals['Mode'] == 'emotion']\n",
    "\n",
    "    labels = roi_p_vals['Condition']\n",
    "\n",
    "    # drop the Mode and Condition columns and sum the rest of the columns\n",
    "    roi_p_vals_sum = roi_p_vals.drop(columns=['Mode', 'Condition']).sum(axis=0)\n",
    "\n",
    "    # create a new dataframe with the regions as the index and the number of significant channels as the values\n",
    "    roi_p_vals_df = pd.DataFrame(roi_p_vals_sum, columns=['Number of Significant Channels'])\n",
    "    roi_p_vals_df.index.name = 'Region'\n",
    "    roi_p_vals_df.reset_index(inplace=True)\n",
    "\n",
    "    # split the Region column into two columns: Region 1 and Region 2\n",
    "    roi_p_vals_df[['Region 1', 'Region 2']] = roi_p_vals_df['Region'].str.split('_', expand=True)\n",
    "    roi_p_vals_df.drop(columns=['Region'], inplace=True)\n",
    "\n",
    "    # create a matrix of the number of significant channels for each region pair\n",
    "    matrix = roi_p_vals_df.pivot(index='Region 1', columns='Region 2', values='Number of Significant Channels')\n",
    "\n",
    "    # fill the NaN values with the symmetric values\n",
    "    matrix = matrix.fillna(matrix.T)\n",
    "\n",
    "    # get rid of the upper triangle of the matrix by setting it to NaN\n",
    "    for i in range(len(matrix.columns)):\n",
    "        for j in range(i):\n",
    "            matrix.iloc[j, i] = np.nan\n",
    "\n",
    "    # plot the heatmap\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    plt.imshow(matrix, cmap='Wistia', aspect='auto')\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.ax.tick_params(labelsize=20)  # Increase colorbar tick size\n",
    "    cbar.set_label('Count of channel pairs', fontsize=24)  # Increase colorbar label size\n",
    "    plt.title('Count of significantly different channel pairs\\n summed across all Emotions by ROI\\'s', fontsize=28)\n",
    "    plt.xticks(ticks=np.arange(len(matrix.columns)), labels=matrix.columns, rotation=45, fontsize=20)\n",
    "    plt.yticks(ticks=np.arange(len(matrix.index)), labels=matrix.index, fontsize=20)\n",
    "    plt.xlabel('ROI', fontsize=24)\n",
    "    plt.ylabel('ROI', fontsize=24)\n",
    "\n",
    "    # Find the locations of the smallest 3 values in the matrix\n",
    "    flat_matrix = matrix.values.flatten()\n",
    "    # Ignore NaNs for sorting\n",
    "    valid_indices = np.where(~np.isnan(flat_matrix))[0]\n",
    "    sorted_indices = valid_indices[np.argsort(flat_matrix[valid_indices])]\n",
    "    least_3_indices = sorted_indices[:3]\n",
    "    least_3_coords = np.unravel_index(least_3_indices, matrix.shape)\n",
    "\n",
    "    # Add asterisks at the locations of the smallest 3 values\n",
    "    for y, x in zip(*least_3_coords):\n",
    "        plt.text(x, y, '*', color='black', fontsize=30, ha='center', va='center')\n",
    "\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig(r'plots\\spectral_connectivity_time\\emotion_analysis\\Count_of_Significant_Channel_Pairs_by_Region.png', dpi=dpi / 2)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = ['face_type', 'emotion']\n",
    "\n",
    "conditions_list = {\n",
    "    'face_type': ['Real', 'Virt'],\n",
    "    'emotion': ['Joy', 'Fear', 'Anger', 'Disgust', 'Sadness', 'Neutral', 'Surprise']\n",
    "}\n",
    "\n",
    "channel_types = ['hbo', 'hbr', 'hbt']\n",
    "\n",
    "dict_channel_types = {\n",
    "    channel_type: idx for idx, channel_type in enumerate(channel_types)\n",
    "}\n",
    "\n",
    "channel_type = 'hbt'\n",
    "\n",
    "# We now have epochs[mode][condition].shape = (n_participants, n_epochs, n_channel_types, n_channels, n_times)\n",
    "epochs = {\n",
    "    mode: {\n",
    "        condition: np.load(f'processed_data/epochs/{mode}_{condition}_epochs.npy')\n",
    "        for condition in conditions_list[mode]\n",
    "    }\n",
    "    for mode in modes\n",
    "}\n",
    "\n",
    "# load the numpy files from disk so we have ind_con[mode][condition].shape = (n_participants, n_channel_types, n_epochs, n_channels)\n",
    "ind_con = {\n",
    "    mode: {\n",
    "        condition: np.load(f'processed_data\\\\spectral_connectivity_time\\\\individual_cons\\\\{mode}_{condition}_con.npy')\n",
    "        for condition in conditions_list[mode]\n",
    "    }\n",
    "    for mode in modes\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Across Participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traditional Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_traditional_raw_across_decoding:\n",
    "    models_to_run = [\n",
    "        HistGradientBoostingClassifier(random_state=42)\n",
    "    ]\n",
    "\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    for model in models_to_run:\n",
    "        model_name = model.__class__.__name__\n",
    "        all_mode_results = {}\n",
    "\n",
    "        for mode in modes:\n",
    "            # get the data for the current mode, shape = (n_participants, n_epochs, n_channels, n_times)\n",
    "            X = np.concatenate([epochs[mode][condition][:, :, dict_channel_types[channel_type], :] for condition in conditions_list[mode]], axis=0)\n",
    "\n",
    "            # get the labels for the current mode, shape = (n_participants * n_epochs,)\n",
    "            y = np.concatenate([\n",
    "                np.repeat(condition, epochs[mode][condition].shape[0] * epochs[mode][condition].shape[1])\n",
    "                for condition in conditions_list[mode]\n",
    "            ], axis=0)\n",
    "\n",
    "            # get the group IDs for the current mode, shape = (n_participants * n_epochs,)\n",
    "            groups = np.concatenate([\n",
    "                np.repeat(participant, epochs[mode][condition].shape[1])\n",
    "                for condition in conditions_list[mode]\n",
    "                for participant in range(epochs[mode][condition].shape[0])\n",
    "            ], axis=0)\n",
    "            \n",
    "            # flatten X to (n_samples, n_features)\n",
    "            X = X.reshape(X.shape[0] * X.shape[1], X.shape[2] * X.shape[3])\n",
    "\n",
    "            # --- parallel Leave-One-Group-Out evaluation ---\n",
    "            pipe = make_pipeline(StandardScaler(), model)\n",
    "            cv_results = cross_validate(\n",
    "                estimator=pipe,\n",
    "                X=X, y=y,\n",
    "                groups=groups,\n",
    "                cv=logo,\n",
    "                scoring='accuracy',\n",
    "                n_jobs=max(n_jobs // 3, 1),\n",
    "                return_train_score=False, \n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            # scale to percentages\n",
    "            logo_scores = list(cv_results['test_score'] * 100)\n",
    "            mean_score = float(np.mean(logo_scores))\n",
    "\n",
    "            all_mode_results[mode] = {\n",
    "                'logo_scores': logo_scores,\n",
    "                'mean_score': mean_score\n",
    "            }\n",
    "\n",
    "        # write out\n",
    "        out_path = f'processed_data/models/raw_across_scores/{model_name}_scores.json'\n",
    "        with open(out_path, 'w') as f:\n",
    "            json.dump(all_mode_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [104, 2912, 2912]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# 3) Cross‐validate\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     45\u001b[39m fold_accuracies = []\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlogo\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my_onehot\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_onehot\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:140\u001b[39m, in \u001b[36mBaseCrossValidator.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m, groups=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    117\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[32m    118\u001b[39m \n\u001b[32m    119\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    138\u001b[39m \u001b[33;03m        The testing set indices for that split.\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     X, y, groups = \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m     indices = np.arange(_num_samples(X))\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter_test_masks(X, y, groups):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:532\u001b[39m, in \u001b[36mindexable\u001b[39m\u001b[34m(*iterables)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[32m    503\u001b[39m \n\u001b[32m    504\u001b[39m \u001b[33;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    528\u001b[39m \u001b[33;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[32m    529\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    531\u001b[39m result = [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:475\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    473\u001b[39m uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    478\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [104, 2912, 2912]"
     ]
    }
   ],
   "source": [
    "if run_dl_raw_across_decoding:\n",
    "    # 1) Prepare cross‐validation splitter\n",
    "    logo = LeaveOneGroupOut()\n",
    "    results_by_mode = {}\n",
    "\n",
    "    for mode in modes:\n",
    "        # -------------------------\n",
    "        # 2) Assemble data arrays\n",
    "        # -------------------------\n",
    "        # Stack all participants & conditions together:\n",
    "        #   X_raw shape before concat: list of arrays, each (n_participants, n_epochs, n_channels, n_times)\n",
    "        X_parts = [\n",
    "            epochs[mode][cond][:, :, dict_channel_types[channel_type], :]\n",
    "            for cond in conditions_list[mode]\n",
    "        ]\n",
    "        # X_parts: list of arrays, each (n_participants, n_epochs, n_channels, n_times)\n",
    "        # Stack along participants and epochs\n",
    "        # Reshape each to (n_participants * n_epochs, n_channels, n_times)\n",
    "        X_parts_reshaped = [\n",
    "            x.reshape(-1, x.shape[2], x.shape[3]) for x in X_parts\n",
    "        ]\n",
    "        X = np.concatenate(X_parts_reshaped, axis=0)  # shape = (n_samples, n_channels, n_times)\n",
    "\n",
    "        # Build integer‐coded label vector y\n",
    "        y_parts = []\n",
    "        groups_parts = []\n",
    "        for cond_idx, cond in enumerate(conditions_list[mode]):\n",
    "            data = epochs[mode][cond][:, :, dict_channel_types[channel_type], :]\n",
    "            n_participants, n_epochs, n_channels, n_times = data.shape\n",
    "\n",
    "            # labels: one integer per epoch of each participant\n",
    "            y_parts.append(\n",
    "                np.full(n_participants * n_epochs, cond_idx, dtype=int)\n",
    "            )\n",
    "            # groups: participant ID repeated for each epoch\n",
    "            groups_parts.append(\n",
    "                np.repeat(np.arange(n_participants), n_epochs)\n",
    "            )\n",
    "\n",
    "        y = np.concatenate(y_parts, axis=0)             # shape = (n_samples,)\n",
    "        groups = np.concatenate(groups_parts, axis=0)   # shape = (n_samples,)\n",
    "\n",
    "        # One‐hot encode labels\n",
    "        num_classes = len(conditions_list[mode])\n",
    "        y_onehot = np.eye(num_classes, dtype=float)[y]  # shape = (n_samples, num_classes)\n",
    "\n",
    "        # -------------------------\n",
    "        # 3) Cross‐validate\n",
    "        # -------------------------\n",
    "        fold_accuracies = []\n",
    "        for train_idx, test_idx in logo.split(X, y, groups):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y_onehot[train_idx], y_onehot[test_idx]\n",
    "\n",
    "            # Build the model\n",
    "            model = tf.keras.Sequential([\n",
    "                tf.keras.layers.LSTM(32,\n",
    "                                     input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "                                     return_sequences=False),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.Dropout(0.3),\n",
    "                tf.keras.layers.Dense(32, activation='relu'),\n",
    "                tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "            ])\n",
    "            model.compile(optimizer='adam',\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            # Early stopping\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=5,\n",
    "                restore_best_weights=True,\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "            # Train\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=30,\n",
    "                batch_size=32,\n",
    "                validation_split=0.2,\n",
    "                callbacks=[early_stop],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            # Evaluate\n",
    "            _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "            fold_accuracies.append(acc * 100)\n",
    "\n",
    "        # Store results\n",
    "        results_by_mode[mode] = {\n",
    "            'fold_accuracies': [float(a) for a in fold_accuracies],\n",
    "            'mean_accuracy': float(np.mean(fold_accuracies)),\n",
    "            'std_accuracy': float(np.std(fold_accuracies))\n",
    "        }\n",
    "\n",
    "    # -------------------------\n",
    "    # 4) Save results to JSON\n",
    "    # -------------------------\n",
    "    output_path = (\n",
    "        'processed_data/models/raw_across_scores/'\n",
    "        f'{model.__class__.__name__}_scores.json'\n",
    "    )\n",
    "    # Ensure all values are native Python types\n",
    "    with open(output_path, 'w') as out_file:\n",
    "        json.dump(results_by_mode, out_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Connectivity Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traditional Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_traditional_con_across_decoding:\n",
    "    models_to_run = [\n",
    "        HistGradientBoostingClassifier(random_state=42)\n",
    "    ]\n",
    "\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    for model in models_to_run:\n",
    "        model_name = model.__class__.__name__\n",
    "        model_scores = {}\n",
    "\n",
    "        for mode in modes:\n",
    "            # --- build X, y, groups as before ---\n",
    "            X_list, y_list, groups_list = [], [], []\n",
    "            for i in range(ind_con[modes[0]][conditions_list[modes[0]][0]].shape[0]):\n",
    "                parts_X, parts_y = [], []\n",
    "                for cond in conditions_list[mode]:\n",
    "                    x = ind_con[mode][cond][i, dict_channel_types[channel_type], :, :, 0]\n",
    "                    parts_X.append(x)\n",
    "                    parts_y.append(np.array([cond] * x.shape[0]))\n",
    "                X_part = np.vstack(parts_X)\n",
    "                y_part = np.hstack(parts_y)\n",
    "                label_map = {lbl: idx for idx, lbl in enumerate(np.unique(y_part))}\n",
    "                y_part = np.array([label_map[lbl] for lbl in y_part])\n",
    "                X_list.append(X_part)\n",
    "                y_list.append(y_part)\n",
    "                groups_list.append(np.full(len(y_part), i))\n",
    "\n",
    "            X = np.concatenate(X_list, axis=0)\n",
    "            y = np.concatenate(y_list, axis=0)\n",
    "            groups = np.concatenate(groups_list, axis=0)\n",
    "\n",
    "            # --- cross_validate in parallel ---\n",
    "            pipe = make_pipeline(StandardScaler(), model)\n",
    "            cv_results = cross_validate(\n",
    "                estimator=pipe,\n",
    "                X=X, y=y,\n",
    "                cv=logo,\n",
    "                groups=groups,\n",
    "                scoring='accuracy',\n",
    "                n_jobs=max(n_jobs // 3, 1),\n",
    "                return_train_score=False, \n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            # convert to percentages\n",
    "            test_scores = cv_results['test_score'] * 100\n",
    "            model_scores[mode] = {\n",
    "                'logo_scores': test_scores.tolist(),\n",
    "                'mean_score': float(np.mean(test_scores))\n",
    "            }\n",
    "\n",
    "        # save out\n",
    "        out_fname = f'processed_data/models/con_across_scores/{model_name}_scores.json'\n",
    "        with open(out_fname, 'w') as f:\n",
    "            json.dump(model_scores, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding Analysis Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_types = ['raw_across_scores', 'con_across_scores']\n",
    "\n",
    "if get_decoding_table_scores_plots:\n",
    "    for score_type in score_types:\n",
    "        # load data from 'processed_data/models' folder\n",
    "        model_scores = {}\n",
    "        # for any csv file in the folder\n",
    "        for file in os.listdir(f'processed_data/models/{score_type}'):\n",
    "            # if the file is a json file\n",
    "            if file.endswith('.json'):\n",
    "                # open the file\n",
    "                with open(f'processed_data/models/{score_type}/{file}', 'r') as f:\n",
    "                    # load the data from the file\n",
    "                    model_scores[file.split('_')[0]] = json.load(f)\n",
    "\n",
    "        # split score_type by '_'\n",
    "        score_type_split = score_type.split('_')\n",
    "        if score_type_split[0] == 'con':\n",
    "            score_type_split[0] = 'Connectivity'\n",
    "        elif score_type_split[0] == 'raw':\n",
    "            score_type_split[0] = 'Raw'\n",
    "\n",
    "        score_type_split[1] = score_type_split[1].capitalize()\n",
    "\n",
    "        # Create a DataFrame from the model scores\n",
    "        model_scores_df = pd.DataFrame([\n",
    "            {'Model': model_name, 'Mode': mode, 'Mean Score': score['mean_score']}\n",
    "            for model_name, scores in model_scores.items()\n",
    "            for mode, score in scores.items()\n",
    "        ])\n",
    "\n",
    "        # Pivot the DataFrame to make 'Model' the first column and each 'Mode' a separate column\n",
    "        model_scores_df = model_scores_df.pivot(index='Model', columns='Mode', values='Mean Score').reset_index()\n",
    "\n",
    "        # Fill NaN values with 0 or any other value if needed\n",
    "        model_scores_df.fillna(np.nan, inplace=True)\n",
    "\n",
    "        # Remove the Mode column name\n",
    "        model_scores_df.columns.name = None\n",
    "\n",
    "        # Reorder the columns to have 'Model', 'face_type', 'emotion'\n",
    "        model_scores_df = model_scores_df[['Model', 'face_type', 'emotion']]\n",
    "\n",
    "        # Round the scores to 2 decimal places\n",
    "        model_scores_df = model_scores_df.round(2)\n",
    "\n",
    "        # Create a matplotlib figure and add a table\n",
    "        fig, ax = plt.subplots(figsize=(6, len(model_scores_df) / 4))\n",
    "        ax.axis('tight')\n",
    "        ax.axis('off')\n",
    "        table = ax.table(cellText=model_scores_df.values, colLabels=model_scores_df.columns, loc='center')\n",
    "\n",
    "        # Set the biggest number in each column to be bold\n",
    "        for i, col in enumerate(model_scores_df.columns):\n",
    "            if col == 'Model':\n",
    "                continue\n",
    "            max_val = model_scores_df[col].max()\n",
    "            for j, val in enumerate(model_scores_df[col]):\n",
    "                if val == max_val:\n",
    "                    table[(j + 1, i)].set_text_props(weight='bold')\n",
    "\n",
    "        # Add a title to the plot\n",
    "        ax.set_title(f'{score_type_split[0]} {score_type_split[1]} Scores (Accuracy%)')\n",
    "\n",
    "        # Save the figure as a PNG file, bbox_inches='tight'\n",
    "        plt.savefig(f'plots/models/tables/{score_type}.png', dpi=dpi, bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Participant/LOGO Scores Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_decoding_individual_scores_plots:\n",
    "    for score_type in score_types:\n",
    "        # load data from 'processed_data/models' folder\n",
    "        model_scores = {}\n",
    "        # for any csv file in the folder\n",
    "        for file in os.listdir(f'processed_data/models/{score_type}'):\n",
    "            # if the file is a json file\n",
    "            if file.endswith('.json'):\n",
    "                # open the file\n",
    "                with open(f'processed_data/models/{score_type}/{file}', 'r') as f:\n",
    "                    # load the data from the file\n",
    "                    model_scores[file.split('_')[0]] = json.load(f)\n",
    "\n",
    "        # split score_type by '_'\n",
    "        score_type_split = score_type.split('_')\n",
    "        if score_type_split[0] == 'con':\n",
    "            score_type_split[0] = 'Connectivity'\n",
    "        elif score_type_split[0] == 'raw':\n",
    "            score_type_split[0] = 'Raw'\n",
    "\n",
    "        score_type_split[1] = score_type_split[1].capitalize()\n",
    "\n",
    "        models = list(model_scores.keys())\n",
    "        modes = list(model_scores[list(model_scores.keys())[0]].keys())\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        colors = plt.cm.tab10.colors  # Use a colormap for distinct colors\n",
    "\n",
    "        # Assign a consistent color to each model\n",
    "        model_colors = {model: colors[idx % len(colors)] for idx, model in enumerate(models)}\n",
    "\n",
    "        for mode_idx, mode in enumerate(modes):\n",
    "            for model_idx, model in enumerate(models):\n",
    "                scores = list(model_scores[model][mode].keys())[0]\n",
    "                vp = plt.violinplot(\n",
    "                    model_scores[model][mode][scores],\n",
    "                    positions=[model_idx + mode_idx * (len(models) + 1)],\n",
    "                    showmeans=True,\n",
    "                    showextrema=True,\n",
    "                    widths=0.5,\n",
    "                    bw_method=0.5,\n",
    "                )\n",
    "                # Set the color for the violin parts\n",
    "                for part in vp['bodies']:\n",
    "                    part.set_facecolor(model_colors[model])\n",
    "                    part.set_edgecolor('black')\n",
    "                    part.set_alpha(0.7)\n",
    "                vp['cmeans'].set_color('black')  # Median line color\n",
    "                vp['cbars'].set_color('black')    # Whisker line color\n",
    "                vp['cmaxes'].set_color('black')   # Max line color\n",
    "                vp['cmins'].set_color('black')    # Min line color\n",
    "\n",
    "        # Set x-ticks and labels\n",
    "        x_ticks = [(len(models) + 1) * i + len(models) / 2 - 0.5 for i in range(len(modes))]\n",
    "        ax.set_xticks(x_ticks)\n",
    "        ax.set_xticklabels(modes)\n",
    "        ax.set_xlabel('Modes')\n",
    "        ax.set_ylabel('Scores')\n",
    "        ax.set_title(f'{score_type_split[0]} {score_type_split[1]} Scores (Accuracy%)')\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.set_yticks(np.arange(0, 101, 10))\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        ax.legend(\n",
    "            handles=[mpatches.Patch(color=model_colors[model], label=model) for model in models],\n",
    "            title='Models',\n",
    "            loc='upper right'\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'plots/models/violin_plots/{score_type}.png', dpi=dpi / 2)\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
